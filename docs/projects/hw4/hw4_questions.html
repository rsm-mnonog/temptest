<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.5">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mario Nonog">
<meta name="dcterms.date" content="2025-06-05">
<meta name="description" content="Machine Learning">

<title>Homework 4 ‚Äì Mario</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ff4371ef257df69894857e99c6ad0d06.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-80016ee63606a2f9ec92f99182a4ea77.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Mario</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../project.html"> 
<span class="menu-text">Homework</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#unsupervised-machine-learning" id="toc-unsupervised-machine-learning" class="nav-link active" data-scroll-target="#unsupervised-machine-learning">UNSUPERVISED MACHINE LEARNING</a>
  <ul class="collapse">
  <li><a href="#introduction-to-k-means-clustering" id="toc-introduction-to-k-means-clustering" class="nav-link" data-scroll-target="#introduction-to-k-means-clustering">üü¶ Introduction to K-Means Clustering</a></li>
  <li><a href="#interpretation-of-k-means-clustering-visuals" id="toc-interpretation-of-k-means-clustering-visuals" class="nav-link" data-scroll-target="#interpretation-of-k-means-clustering-visuals">üß† Interpretation of K-Means Clustering Visuals</a></li>
  <li><a href="#apropriate-number-of-cluster-k" id="toc-apropriate-number-of-cluster-k" class="nav-link" data-scroll-target="#apropriate-number-of-cluster-k">Apropriate Number of Cluster K</a></li>
  <li><a href="#interpretation-of-cluster-evaluation-metrics" id="toc-interpretation-of-cluster-evaluation-metrics" class="nav-link" data-scroll-target="#interpretation-of-cluster-evaluation-metrics">üìä Interpretation of Cluster Evaluation Metrics</a></li>
  <li><a href="#visualizing-k-means-with-animation" id="toc-visualizing-k-means-with-animation" class="nav-link" data-scroll-target="#visualizing-k-means-with-animation">üåÄ Visualizing K-Means with Animation</a></li>
  </ul></li>
  <li><a href="#supervised-machine-learning" id="toc-supervised-machine-learning" class="nav-link" data-scroll-target="#supervised-machine-learning">SUPERVISED MACHINE LEARNING</a>
  <ul class="collapse">
  <li><a href="#key-drivers-analysis-of-customer-satisfaction" id="toc-key-drivers-analysis-of-customer-satisfaction" class="nav-link" data-scroll-target="#key-drivers-analysis-of-customer-satisfaction">üîç Key Drivers Analysis of Customer Satisfaction</a></li>
  <li><a href="#my-interpretation-of-the-key-driver-analysis" id="toc-my-interpretation-of-the-key-driver-analysis" class="nav-link" data-scroll-target="#my-interpretation-of-the-key-driver-analysis">üîç My Interpretation of the Key Driver Analysis</a></li>
  <li><a href="#advanced-model-based-importance-measures-challenge" id="toc-advanced-model-based-importance-measures-challenge" class="nav-link" data-scroll-target="#advanced-model-based-importance-measures-challenge">üß† Advanced Model-Based Importance Measures (Challenge)</a></li>
  <li><a href="#my-interpretation-of-the-driver-importance-table" id="toc-my-interpretation-of-the-driver-importance-table" class="nav-link" data-scroll-target="#my-interpretation-of-the-driver-importance-table">üß† My Interpretation of the Driver Importance Table</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Homework 4</h1>
</div>

<div>
  <div class="description">
    Machine Learning
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Mario Nonog </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 5, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<!-- _todo: do two analyses.  Do one of either 1a or 1b, AND one of either 2a or 2b._ -->
<p>Machine learning offers a powerful toolkit for uncovering patterns in data and making informed predictions or decisions. In this assignment, I explore both unsupervised and supervised learning methods by applying them to real-world datasets provided for analysis. The goal is to gain a deeper understanding of how these algorithms work under the hood by implementing them from scratch and critically interpreting their outputs.</p>
<p>The assignment is structured in two parts: ‚Ä¢ Unsupervised Learning focuses on discovering natural groupings within data without labeled outcomes. I explore this through a custom implementation of the K-Means algorithm (or alternatively, a latent-class multinomial logit model), analyzing cluster formation in the Palmer Penguins dataset. ‚Ä¢ Supervised Learning involves predicting outcomes based on input features. Here, I either implement K-Nearest Neighbors (KNN) from the ground up or replicate a comprehensive key driver analysis of customer satisfaction using regression- and model-based interpretability metrics. This analysis uses the key drivers dataset and draws inspiration from lecture slides.</p>
<p>Throughout this report, I aim to balance technical rigor with interpretability, providing both visual and numerical summaries of the models‚Äô behavior. I also reflect on the limitations, assumptions, and practical takeaways from each method, making the report accessible to both technical and non-technical readers.</p>
<section id="unsupervised-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="unsupervised-machine-learning">UNSUPERVISED MACHINE LEARNING</h2>
<section id="introduction-to-k-means-clustering" class="level3">
<h3 class="anchored" data-anchor-id="introduction-to-k-means-clustering">üü¶ Introduction to K-Means Clustering</h3>
<p>Clustering is a fundamental unsupervised learning technique used to identify natural groupings within data. In this section, we explore the K-Means algorithm ‚Äî a widely used partitioning method that aims to minimize the within-cluster variance by iteratively updating centroids. To deepen our understanding, we implement the algorithm from scratch and visualize each iterative step to observe how centroids converge. We apply our custom K-Means implementation to the Palmer Penguins dataset, focusing specifically on the bill_length_mm and flipper_length_mm features. Finally, we compare our results to the built-in KMeans function from Python‚Äôs scikit-learn library to evaluate accuracy and consistency. <!-- _todo: write your own code to implement the k-means algorithm.  Make plots of the various steps the algorithm takes so you can "see" the algorithm working.  Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables.  Compare your results to the built-in `kmeans` function in R or Python._ --></p>
<div id="bf5fb2a4" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and clean the dataset</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>penguins_df <span class="op">=</span> pd.read_csv(<span class="st">'other_docs/palmer_penguins.csv'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> penguins_df[[<span class="st">'bill_length_mm'</span>, <span class="st">'flipper_length_mm'</span>]].dropna().values</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom K-means implementation</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kmeans_custom(data, k<span class="op">=</span><span class="dv">3</span>, max_iters<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    centroids <span class="op">=</span> data[np.random.choice(<span class="bu">len</span>(data), k, replace<span class="op">=</span><span class="va">False</span>)]</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> [centroids.copy()]</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_iters):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        distances <span class="op">=</span> np.linalg.norm(data[:, np.newaxis] <span class="op">-</span> centroids, axis<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        clusters <span class="op">=</span> np.argmin(distances, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        new_centroids <span class="op">=</span> np.array([data[clusters <span class="op">==</span> i].mean(axis<span class="op">=</span><span class="dv">0</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k)])</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        history.append(new_centroids.copy())</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.allclose(centroids, new_centroids):</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        centroids <span class="op">=</span> new_centroids</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> centroids, clusters, history</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Run custom K-means</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>centroids_final, cluster_labels, history <span class="op">=</span> kmeans_custom(data, k<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot steps of custom K-means</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="bu">len</span>(history), <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="bu">len</span>(history) <span class="op">*</span> <span class="dv">4</span>))</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, centroids <span class="kw">in</span> <span class="bu">enumerate</span>(history):</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    axs[i].scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'gray'</span>, s<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>    axs[i].scatter(centroids[:, <span class="dv">0</span>], centroids[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    axs[i].set_title(<span class="ss">f'Step </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    axs[i].set_xlabel(<span class="st">'Bill Length (mm)'</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    axs[i].set_ylabel(<span class="st">'Flipper Length (mm)'</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Built-in KMeans</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>kmeans_builtin <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>builtin_labels <span class="op">=</span> kmeans_builtin.fit_predict(data)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot comparison of custom vs built-in</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom K-means</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], c<span class="op">=</span>cluster_labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].scatter(centroids_final[:, <span class="dv">0</span>], centroids_final[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">'Custom K-Means'</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_xlabel(<span class="st">'Bill Length (mm)'</span>)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_ylabel(<span class="st">'Flipper Length (mm)'</span>)</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Built-in K-means</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], c<span class="op">=</span>builtin_labels, cmap<span class="op">=</span><span class="st">'viridis'</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].scatter(kmeans_builtin.cluster_centers_[:, <span class="dv">0</span>], kmeans_builtin.cluster_centers_[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">'Built-in KMeans (sklearn)'</span>)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">'Bill Length (mm)'</span>)</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_ylabel(<span class="st">'Flipper Length (mm)'</span>)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw4_questions_files/figure-html/cell-2-output-1.png" width="565" height="4212" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw4_questions_files/figure-html/cell-2-output-2.png" width="1141" height="468" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<!-- <!-- _todo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,...,7). What is the "right" number of clusters as suggested by these two metrics?_ -->
</section>
<section id="interpretation-of-k-means-clustering-visuals" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-k-means-clustering-visuals">üß† Interpretation of K-Means Clustering Visuals</h3>
<p>üîÑ K-Means Convergence Process (Step-by-Step GIF-like Sequence) ‚Ä¢ Description: The tall vertical figure shows the movement of centroids (red X‚Äôs) over a series of steps (Step 0 to Step 10) during your custom K-Means algorithm. ‚Ä¢ Initial State (Step 0): The centroids are randomly initialized and poorly positioned relative to the data clusters. ‚Ä¢ Early Iterations (Steps 1‚Äì4): You can see the centroids move quickly toward the center of dense data regions. This indicates the algorithm is beginning to form tighter clusters. ‚Ä¢ Later Iterations (Steps 5‚Äì10): The centroid movement gradually slows down and stabilizes. At this point, data point assignments no longer change significantly, indicating convergence. ‚Ä¢ Final State (Step 10): All centroids have settled at positions that represent the center of their respective clusters. The cluster structure is clearly aligned with the natural groupings in the data.</p>
<p>‚úÖ This sequence demonstrates successful implementation and convergence of your custom K-Means algorithm.</p>
<p>‚∏ª</p>
<p>‚öñÔ∏è Comparison: Custom vs.&nbsp;Built-in KMeans (Side-by-Side Plot) ‚Ä¢ Left Plot (Custom K-Means): Each data point is colored by its final cluster assignment, and the centroids are clearly located in the densest areas of their respective clusters. ‚Ä¢ Right Plot (scikit-learn Built-in): The result is nearly identical to your custom implementation ‚Äî clusters are almost perfectly aligned and centroids occupy similar positions.</p>
<p>Key Observations: ‚Ä¢ Both methods captured three natural clusters, consistent with the known species structure in the Palmer Penguins dataset. ‚Ä¢ Cluster separation is clean, especially along the flipper length dimension. ‚Ä¢ Your custom implementation is highly consistent with the built-in version, validating its correctness.</p>
<p>‚∏ª</p>
<p>‚úÖ Summary ‚Ä¢ Your custom K-Means algorithm not only converged properly but also matched the performance and output of the built-in KMeans from scikit-learn. ‚Ä¢ The step-by-step visualization helps demystify the iterative process of centroid updates, offering valuable pedagogical insight. ‚Ä¢ The comparison confirms that feature selection (bill length and flipper length) is appropriate for uncovering species-level clusters in the penguin dataset.</p>
</section>
<section id="apropriate-number-of-cluster-k" class="level3">
<h3 class="anchored" data-anchor-id="apropriate-number-of-cluster-k">Apropriate Number of Cluster K</h3>
<p>After implementing and testing the K-Means algorithm, the next step is to determine the most appropriate number of clusters (k) for the data. Two commonly used metrics for evaluating cluster quality are the within-cluster sum of squares (WCSS) and the silhouette score. WCSS measures the compactness of clusters ‚Äî lower values indicate tighter groupings ‚Äî while the silhouette score assesses how well-separated the clusters are, balancing cohesion and separation. In this section, we compute both metrics across a range of cluster counts (k = 2 to 7) using the Palmer Penguins dataset. The goal is to identify the ‚Äúelbow‚Äù point in the WCSS plot and the peak silhouette value, which together guide us in selecting the optimal number of clusters that best represent the underlying structure in the data.</p>
<div id="afdd9cd7" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and clean the dataset</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>penguins_df <span class="op">=</span> pd.read_csv(<span class="st">'other_docs/palmer_penguins.csv'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> penguins_df[[<span class="st">'bill_length_mm'</span>, <span class="st">'flipper_length_mm'</span>]].dropna().values</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare lists to store metrics</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>wcss <span class="op">=</span> []  <span class="co"># Within-cluster sum of squares</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>silhouette_scores <span class="op">=</span> []</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Try different numbers of clusters</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>K_values <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">8</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> K_values:</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> model.fit_predict(data)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Append metrics</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    wcss.append(model.inertia_)  <span class="co"># WCSS is inertia</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    silhouette_scores.append(silhouette_score(data, labels))</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot WCSS and Silhouette Scores</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># WCSS plot</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].plot(K_values, wcss, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">'Within-Cluster Sum of Squares (WCSS)'</span>)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_ylabel(<span class="st">'WCSS'</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Silhouette Score plot</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].plot(K_values, silhouette_scores, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">'Silhouette Scores'</span>)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">'Number of Clusters (k)'</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_ylabel(<span class="st">'Silhouette Score'</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw4_questions_files/figure-html/cell-3-output-1.png" width="1141" height="468" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="interpretation-of-cluster-evaluation-metrics" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-cluster-evaluation-metrics">üìä Interpretation of Cluster Evaluation Metrics</h3>
<p>üîπ Left Plot: Within-Cluster Sum of Squares (WCSS) ‚Ä¢ What it shows: WCSS measures the total variance within each cluster. As k increases, WCSS naturally decreases because points are grouped into more localized clusters. ‚Ä¢ Elbow Method: There is a visible ‚Äúelbow‚Äù at k = 3 ‚Äî this is the point where the rate of WCSS reduction slows noticeably. This suggests that using 3 clusters captures most of the structure in the data without overfitting. ‚Ä¢ Interpretation: The elbow at k = 3 is a strong indicator that three clusters represent a good balance between model simplicity and explanatory power.</p>
<p>‚∏ª</p>
<p>üîπ Right Plot: Silhouette Scores ‚Ä¢ What it shows: The silhouette score evaluates how well each point fits within its cluster versus other clusters. It ranges from -1 to 1; higher values indicate better-defined, well-separated clusters. ‚Ä¢ Peak Value: The highest silhouette score occurs at k = 2, indicating tight and well-separated clusters in that configuration. ‚Ä¢ Score Behavior: The silhouette score drops significantly after k = 2, and continues to decline gradually. At k = 3, it remains reasonably high but lower than at k = 2. ‚Ä¢ Interpretation: While k = 2 yields the best-defined clusters, it may underrepresent the true complexity of the dataset. k = 3 offers a compromise ‚Äî it aligns with the elbow method and is still supported by a relatively high silhouette score.</p>
<p>‚∏ª</p>
<p>‚úÖ Conclusion ‚Ä¢ Recommended number of clusters: k = 3 is the optimal choice when balancing both the WCSS (elbow method) and silhouette score. ‚Ä¢ Rationale: While k = 2 shows the best silhouette, the additional cluster in k = 3 likely reflects meaningful substructure (e.g., the three penguin species), especially when combined with domain knowledge.</p>
<!-- _If you want a challenge, add your plots as an animated gif on your website so that the result looks something like [this](https://www.youtube.com/shorts/XCsoWZU9oN8)._ -->
</section>
<section id="visualizing-k-means-with-animation" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-k-means-with-animation">üåÄ Visualizing K-Means with Animation</h3>
<p>To enhance interpretability and demonstrate how the K-Means algorithm converges, we create an animated visualization of the clustering process. This animation illustrates how centroids shift over iterations and how data points are reassigned until the algorithm stabilizes. By saving each iteration as an image and compiling them into a GIF, we can clearly observe the step-by-step progression of centroid movement and cluster formation. This dynamic approach offers an intuitive understanding of how K-Means operates, especially in contrast to static plots, and aligns with the spirit of interactive data storytelling.</p>
<div id="7473c991" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> imageio.v2 <span class="im">as</span> imageio  <span class="co"># Use v2 to avoid deprecation warnings</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and clean the dataset</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>penguins_df <span class="op">=</span> pd.read_csv(<span class="st">'other_docs/palmer_penguins.csv'</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> penguins_df[[<span class="st">'bill_length_mm'</span>, <span class="st">'flipper_length_mm'</span>]].dropna().values</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom K-means implementation</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kmeans_custom(data, k<span class="op">=</span><span class="dv">3</span>, max_iters<span class="op">=</span><span class="dv">10</span>):  <span class="co"># Keep max_iters small for animation</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">42</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    centroids <span class="op">=</span> data[np.random.choice(<span class="bu">len</span>(data), k, replace<span class="op">=</span><span class="va">False</span>)]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> [centroids.copy()]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_iters):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        distances <span class="op">=</span> np.linalg.norm(data[:, np.newaxis] <span class="op">-</span> centroids, axis<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        clusters <span class="op">=</span> np.argmin(distances, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        new_centroids <span class="op">=</span> np.array([data[clusters <span class="op">==</span> i].mean(axis<span class="op">=</span><span class="dv">0</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(k)])</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        history.append(new_centroids.copy())</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.allclose(centroids, new_centroids):</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        centroids <span class="op">=</span> new_centroids</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> clusters, history</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Run K-means</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>clusters, history <span class="op">=</span> kmeans_custom(data, k<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Create folder for frames</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>frame_dir <span class="op">=</span> <span class="st">"kmeans_frames"</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>os.makedirs(frame_dir, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>filenames <span class="op">=</span> []</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Save each step as an image</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, centroids <span class="kw">in</span> <span class="bu">enumerate</span>(history):</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>), dpi<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    plt.scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    plt.scatter(centroids[:, <span class="dv">0</span>], centroids[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"K-Means Step </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Bill Length (mm)"</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">"Flipper Length (mm)"</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    fname <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>frame_dir<span class="sc">}</span><span class="ss">/frame_</span><span class="sc">{</span>i<span class="sc">:02d}</span><span class="ss">.png"</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    plt.savefig(fname, bbox_inches<span class="op">=</span><span class="st">'tight'</span>)</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    filenames.append(fname)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Create animated GIF</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>gif_path <span class="op">=</span> <span class="st">"kmeans_animation.gif"</span></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> imageio.get_writer(gif_path, mode<span class="op">=</span><span class="st">'I'</span>, duration<span class="op">=</span><span class="fl">0.8</span>) <span class="im">as</span> writer:</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> filename <span class="kw">in</span> filenames:</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> imageio.imread(filename)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>        writer.append_data(image)</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"GIF saved to </span><span class="sc">{</span>gif_path<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>GIF saved to kmeans_animation.gif</code></pre>
</div>
</div>
<!-- ## 1b. Latent-Class MNL

_todo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57._

_The data provides anonymized consumer identifiers (`id`), a vector indicating the chosen product (`y1`:`y4`), a vector indicating if any products were "featured" in the store as a form of advertising (`f1`:`f4`), and the products' prices in price-per-ounce (`p1`:`p4`). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1's purchase.  Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current "wide" format into a "long" format._

_todo: Fit the standard MNL model on these data.  Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes._

_todo: How many classes are suggested by the $BIC = -2*\ell_n  + k*log(n)$? (where $\ell_n$ is the log-likelihood, $n$ is the sample size, and $k$ is the number of parameters.) The Bayesian-Schwarz Information Criterion [link](https://en.wikipedia.org/wiki/Bayesian_information_criterion) is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate -- akin to the adjusted R-squared for the linear regression model. Note, that a **lower** BIC indicates a better model fit, accounting for the number of parameters in the model._

_todo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC._ -->
<!-- ## 2a. K Nearest Neighbors

<!-- _todo: implement KNN by hand._ -->
<!-- _todo: check your function by..._  -->
</section>
</section>
<section id="supervised-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="supervised-machine-learning">SUPERVISED MACHINE LEARNING</h2>
<section id="key-drivers-analysis-of-customer-satisfaction" class="level3">
<h3 class="anchored" data-anchor-id="key-drivers-analysis-of-customer-satisfaction">üîç Key Drivers Analysis of Customer Satisfaction</h3>
<!-- _todo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, "usefulness", Shapley values for a linear regression, Johnson's relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations "by hand."_ -->
<p>Understanding what drives customer satisfaction is critical for making strategic improvements in product and service delivery. In this section, we replicate the driver importance analysis shown on Slide 75 of the lecture slides using the data_for_drivers_analysis.csv dataset. Our target variable is satisfaction, and we evaluate the importance of nine key drivers using a comprehensive suite of methods. These include Pearson correlations, standardized regression coefficients, usefulness scores via permutation importance, Shapley value approximations (LMG), Johnson‚Äôs relative weights (Œµ), and mean decrease in Gini from a random forest. Together, these diverse techniques offer a well-rounded view of variable influence, capturing both linear associations and non-linear predictive power. This analysis not only validates the theoretical concepts covered in class but also provides a practical benchmark for feature attribution in real-world modeling.</p>
<p>‚∏ª</p>
<div id="2377cb9a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"other_docs/data_for_drivers_analysis.csv"</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features and target</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [<span class="st">'trust'</span>, <span class="st">'build'</span>, <span class="st">'differs'</span>, <span class="st">'easy'</span>, <span class="st">'appealing'</span>, <span class="st">'rewarding'</span>, <span class="st">'popular'</span>, <span class="st">'service'</span>, <span class="st">'impact'</span>]</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'satisfaction'</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean data</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>df_clean <span class="op">=</span> df.dropna(subset<span class="op">=</span>features <span class="op">+</span> [target])</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_clean[features]</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_clean[target]</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize X for regression and PCA</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Linear Regression (Standardized Coefficients)</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>linreg <span class="op">=</span> LinearRegression()</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>linreg.fit(X_scaled, y)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>std_coefficients <span class="op">=</span> pd.Series(linreg.coef_, index<span class="op">=</span>features)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Pearson Correlations</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>pearson_corr <span class="op">=</span> X.corrwith(y)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Random Forest</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>rf.fit(X, y)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>gini_importance <span class="op">=</span> pd.Series(rf.feature_importances_ <span class="op">*</span> <span class="dv">100</span>, index<span class="op">=</span>features)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Permutation Importance (Usefulness)</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>perm <span class="op">=</span> permutation_importance(rf, X, y, n_repeats<span class="op">=</span><span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>perm_importance <span class="op">=</span> pd.Series(perm.importances_mean <span class="op">*</span> <span class="dv">100</span>, index<span class="op">=</span>features)</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co"># --- LMG / Shapley Approximation</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> approximate_lmg(X, y, num_samples<span class="op">=</span><span class="dv">200</span>):</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    var_names <span class="op">=</span> <span class="bu">list</span>(X.columns)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> <span class="bu">len</span>(var_names)</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    lmg_scores <span class="op">=</span> pd.Series(np.zeros(k), index<span class="op">=</span>var_names)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_samples):</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        perm <span class="op">=</span> random.sample(var_names, k)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        prev_X <span class="op">=</span> pd.DataFrame()</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        prev_r2 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> var <span class="kw">in</span> perm:</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>            current_X <span class="op">=</span> pd.concat([prev_X, X[[var]]], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> LinearRegression().fit(current_X, y)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>            new_r2 <span class="op">=</span> r2_score(y, model.predict(current_X))</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>            lmg_scores[var] <span class="op">+=</span> (new_r2 <span class="op">-</span> prev_r2)</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>            prev_X <span class="op">=</span> current_X</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>            prev_r2 <span class="op">=</span> new_r2</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>    lmg_scores <span class="op">/=</span> num_samples</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lmg_scores <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>lmg_approx <span class="op">=</span> approximate_lmg(X, y, num_samples<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Johnson's Relative Weights</span></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>eigenvalues <span class="op">=</span> pca.explained_variance_</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>loadings <span class="op">=</span> pca.components_.T</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> linreg.coef_</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> np.<span class="bu">sum</span>((loadings <span class="op">*</span> beta.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">**</span> <span class="dv">2</span> <span class="op">*</span> eigenvalues, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>rel_weights <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> weights <span class="op">/</span> np.<span class="bu">sum</span>(weights)</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a>rel_weights_series <span class="op">=</span> pd.Series(rel_weights, index<span class="op">=</span>features)</span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Combine All Results</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pearson Corr (%)"</span>: pearson_corr <span class="op">*</span> <span class="dv">100</span>,</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std Coefficients (%)"</span>: std_coefficients <span class="op">*</span> <span class="dv">100</span>,</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Usefulness (Permutation) (%)"</span>: perm_importance,</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>    <span class="st">"LMG / Shapley (%)"</span>: lmg_approx,</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Johnson's Epsilon (%)"</span>: rel_weights_series,</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>    <span class="st">"RF Gini (%)"</span>: gini_importance</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>}).<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort columns by average importance for presentation (optional)</span></span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> results.sort_values(by<span class="op">=</span><span class="st">"LMG / Shapley (%)"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Style the DataFrame for better presentation</span></span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>styled_table <span class="op">=</span> results.style <span class="op">\</span></span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>    .background_gradient(cmap<span class="op">=</span><span class="st">"YlGnBu"</span>, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">\</span></span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">format</span>(<span class="st">"</span><span class="sc">{:.1f}</span><span class="st">"</span>) <span class="op">\</span></span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>    .set_caption(<span class="st">"üí° Key Drivers of Customer Satisfaction (Multi-Metric Comparison)"</span>) <span class="op">\</span></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>    .set_properties(<span class="op">**</span>{<span class="st">"text-align"</span>: <span class="st">"center"</span>}) <span class="op">\</span></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>    .set_table_styles([</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"selector"</span>: <span class="st">"th"</span>, <span class="st">"props"</span>: [(<span class="st">"text-align"</span>, <span class="st">"center"</span>)]},</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"selector"</span>: <span class="st">"caption"</span>, <span class="st">"props"</span>: [(<span class="st">"caption-side"</span>, <span class="st">"top"</span>), (<span class="st">"font-weight"</span>, <span class="st">"bold"</span>)]}</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the styled table</span></span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a>styled_table</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<style type="text/css">
#T_1554e th {
  text-align: center;
}
#T_1554e caption {
  caption-side: top;
  font-weight: bold;
}
#T_1554e_row0_col0 {
  background-color: #0b1f5e;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row0_col1, #T_1554e_row0_col3, #T_1554e_row0_col4, #T_1554e_row1_col0, #T_1554e_row1_col2, #T_1554e_row1_col5 {
  background-color: #081d58;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row0_col2 {
  background-color: #2165ab;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row0_col5 {
  background-color: #2351a2;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row1_col1 {
  background-color: #1e2e85;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row1_col3 {
  background-color: #203089;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row1_col4 {
  background-color: #23499e;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row2_col0 {
  background-color: #162874;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row2_col1 {
  background-color: #1f7ab5;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row2_col2 {
  background-color: #216bae;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row2_col3 {
  background-color: #1f78b4;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row2_col4 {
  background-color: #50bbc2;
  color: #000000;
  text-align: center;
}
#T_1554e_row2_col5 {
  background-color: #1d90c0;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row3_col0 {
  background-color: #44b7c4;
  color: #f1f1f1;
  text-align: center;
}
#T_1554e_row3_col1 {
  background-color: #e9f7b1;
  color: #000000;
  text-align: center;
}
#T_1554e_row3_col2 {
  background-color: #c6e9b4;
  color: #000000;
  text-align: center;
}
#T_1554e_row3_col3, #T_1554e_row4_col3, #T_1554e_row6_col2 {
  background-color: #d4eeb3;
  color: #000000;
  text-align: center;
}
#T_1554e_row3_col4 {
  background-color: #fcfed1;
  color: #000000;
  text-align: center;
}
#T_1554e_row3_col5 {
  background-color: #d6efb3;
  color: #000000;
  text-align: center;
}
#T_1554e_row4_col0 {
  background-color: #61c2bf;
  color: #000000;
  text-align: center;
}
#T_1554e_row4_col1 {
  background-color: #cbebb4;
  color: #000000;
  text-align: center;
}
#T_1554e_row4_col2 {
  background-color: #d9f0b3;
  color: #000000;
  text-align: center;
}
#T_1554e_row4_col4 {
  background-color: #f5fbc4;
  color: #000000;
  text-align: center;
}
#T_1554e_row4_col5, #T_1554e_row6_col1, #T_1554e_row6_col4, #T_1554e_row7_col2, #T_1554e_row8_col0, #T_1554e_row8_col3 {
  background-color: #ffffd9;
  color: #000000;
  text-align: center;
}
#T_1554e_row5_col0 {
  background-color: #c8e9b4;
  color: #000000;
  text-align: center;
}
#T_1554e_row5_col1 {
  background-color: #eef8b3;
  color: #000000;
  text-align: center;
}
#T_1554e_row5_col2 {
  background-color: #bde5b5;
  color: #000000;
  text-align: center;
}
#T_1554e_row5_col3, #T_1554e_row6_col3 {
  background-color: #e3f4b2;
  color: #000000;
  text-align: center;
}
#T_1554e_row5_col4 {
  background-color: #fcfed3;
  color: #000000;
  text-align: center;
}
#T_1554e_row5_col5 {
  background-color: #ceecb3;
  color: #000000;
  text-align: center;
}
#T_1554e_row6_col0 {
  background-color: #b4e2b6;
  color: #000000;
  text-align: center;
}
#T_1554e_row6_col5 {
  background-color: #d3eeb3;
  color: #000000;
  text-align: center;
}
#T_1554e_row7_col0 {
  background-color: #e1f3b2;
  color: #000000;
  text-align: center;
}
#T_1554e_row7_col1 {
  background-color: #dbf1b2;
  color: #000000;
  text-align: center;
}
#T_1554e_row7_col3 {
  background-color: #f0f9b8;
  color: #000000;
  text-align: center;
}
#T_1554e_row7_col4 {
  background-color: #f9fdcb;
  color: #000000;
  text-align: center;
}
#T_1554e_row7_col5 {
  background-color: #f7fcc7;
  color: #000000;
  text-align: center;
}
#T_1554e_row8_col1 {
  background-color: #f2fabc;
  color: #000000;
  text-align: center;
}
#T_1554e_row8_col2 {
  background-color: #cfecb3;
  color: #000000;
  text-align: center;
}
#T_1554e_row8_col4 {
  background-color: #fdfed5;
  color: #000000;
  text-align: center;
}
#T_1554e_row8_col5 {
  background-color: #edf8b1;
  color: #000000;
  text-align: center;
}
</style>

<div id="T_1554e" class="quarto-float quarto-figure quarto-figure-center anchored" data-quarto-postprocess="true">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="T_1554e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: üí° Key Drivers of Customer Satisfaction (Multi-Metric Comparison)
</figcaption>
<div aria-describedby="T_1554e-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table id="T_1554e" class="caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_1554e_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Pearson Corr (%)</th>
<th id="T_1554e_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Std Coefficients (%)</th>
<th id="T_1554e_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Usefulness (Permutation) (%)</th>
<th id="T_1554e_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">LMG / Shapley (%)</th>
<th id="T_1554e_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">Johnson's Epsilon (%)</th>
<th id="T_1554e_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">RF Gini (%)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_1554e_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">impact</td>
<td id="T_1554e_row0_col0" class="data row0 col0">25.5</td>
<td id="T_1554e_row0_col1" class="data row0 col1">15.0</td>
<td id="T_1554e_row0_col2" class="data row0 col2">15.4</td>
<td id="T_1554e_row0_col3" class="data row0 col3">2.4</td>
<td id="T_1554e_row0_col4" class="data row0 col4">40.4</td>
<td id="T_1554e_row0_col5" class="data row0 col5">14.1</td>
</tr>
<tr class="even">
<td id="T_1554e_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">trust</td>
<td id="T_1554e_row1_col0" class="data row1 col0">25.6</td>
<td id="T_1554e_row1_col1" class="data row1 col1">13.6</td>
<td id="T_1554e_row1_col2" class="data row1 col2">17.2</td>
<td id="T_1554e_row1_col3" class="data row1 col3">2.2</td>
<td id="T_1554e_row1_col4" class="data row1 col4">32.8</td>
<td id="T_1554e_row1_col5" class="data row1 col5">15.6</td>
</tr>
<tr class="odd">
<td id="T_1554e_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">service</td>
<td id="T_1554e_row2_col0" class="data row2 col0">25.1</td>
<td id="T_1554e_row2_col1" class="data row2 col1">10.4</td>
<td id="T_1554e_row2_col2" class="data row2 col2">15.3</td>
<td id="T_1554e_row2_col3" class="data row2 col3">1.8</td>
<td id="T_1554e_row2_col4" class="data row2 col4">19.1</td>
<td id="T_1554e_row2_col5" class="data row2 col5">13.0</td>
</tr>
<tr class="even">
<td id="T_1554e_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">easy</td>
<td id="T_1554e_row3_col0" class="data row3 col0">21.3</td>
<td id="T_1554e_row3_col1" class="data row3 col1">2.6</td>
<td id="T_1554e_row3_col2" class="data row3 col2">12.2</td>
<td id="T_1554e_row3_col3" class="data row3 col3">0.9</td>
<td id="T_1554e_row3_col4" class="data row3 col4">1.2</td>
<td id="T_1554e_row3_col5" class="data row3 col5">10.0</td>
</tr>
<tr class="odd">
<td id="T_1554e_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">appealing</td>
<td id="T_1554e_row4_col0" class="data row4 col0">20.8</td>
<td id="T_1554e_row4_col1" class="data row4 col1">4.0</td>
<td id="T_1554e_row4_col2" class="data row4 col2">11.8</td>
<td id="T_1554e_row4_col3" class="data row4 col3">0.9</td>
<td id="T_1554e_row4_col4" class="data row4 col4">2.8</td>
<td id="T_1554e_row4_col5" class="data row4 col5">8.6</td>
</tr>
<tr class="even">
<td id="T_1554e_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">build</td>
<td id="T_1554e_row5_col0" class="data row5 col0">19.2</td>
<td id="T_1554e_row5_col1" class="data row5 col1">2.3</td>
<td id="T_1554e_row5_col2" class="data row5 col2">12.3</td>
<td id="T_1554e_row5_col3" class="data row5 col3">0.8</td>
<td id="T_1554e_row5_col4" class="data row5 col4">1.0</td>
<td id="T_1554e_row5_col5" class="data row5 col5">10.2</td>
</tr>
<tr class="odd">
<td id="T_1554e_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">rewarding</td>
<td id="T_1554e_row6_col0" class="data row6 col0">19.5</td>
<td id="T_1554e_row6_col1" class="data row6 col1">0.6</td>
<td id="T_1554e_row6_col2" class="data row6 col2">11.9</td>
<td id="T_1554e_row6_col3" class="data row6 col3">0.8</td>
<td id="T_1554e_row6_col4" class="data row6 col4">0.1</td>
<td id="T_1554e_row6_col5" class="data row6 col5">10.1</td>
</tr>
<tr class="even">
<td id="T_1554e_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">differs</td>
<td id="T_1554e_row7_col0" class="data row7 col0">18.5</td>
<td id="T_1554e_row7_col1" class="data row7 col1">3.3</td>
<td id="T_1554e_row7_col2" class="data row7 col2">10.5</td>
<td id="T_1554e_row7_col3" class="data row7 col3">0.7</td>
<td id="T_1554e_row7_col4" class="data row7 col4">1.9</td>
<td id="T_1554e_row7_col5" class="data row7 col5">9.0</td>
</tr>
<tr class="odd">
<td id="T_1554e_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">popular</td>
<td id="T_1554e_row8_col0" class="data row8 col0">17.1</td>
<td id="T_1554e_row8_col1" class="data row8 col1">1.9</td>
<td id="T_1554e_row8_col2" class="data row8 col2">12.0</td>
<td id="T_1554e_row8_col3" class="data row8 col3">0.5</td>
<td id="T_1554e_row8_col4" class="data row8 col4">0.7</td>
<td id="T_1554e_row8_col5" class="data row8 col5">9.5</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
<!-- _If you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables._ -->
</section>
<section id="my-interpretation-of-the-key-driver-analysis" class="level3">
<h3 class="anchored" data-anchor-id="my-interpretation-of-the-key-driver-analysis">üîç My Interpretation of the Key Driver Analysis</h3>
<p>To understand what drives customer satisfaction, I evaluated nine predictors using a diverse set of metrics: Pearson correlation, standardized regression coefficients, permutation importance, Shapley approximations (LMG), Johnson‚Äôs relative weights, and Random Forest Gini importance. This gave me a well-rounded view of each variable‚Äôs influence from both statistical and machine learning perspectives.</p>
<p>‚∏ª</p>
<p>üìà 1. Pearson Correlation</p>
<p>I found that trust, impact, and service had the strongest direct linear relationships with satisfaction, each with correlations above 25%. This tells me that customers who rated these attributes higher also reported higher satisfaction.</p>
<p>‚∏ª</p>
<p>‚öôÔ∏è 2. Standardized Coefficients</p>
<p>Looking at the standardized coefficients from the regression model, impact stood out the most (15.0%), followed by trust (13.6%) and service (10.4%). On the other hand, features like rewarding and build had very little influence once I controlled for other variables.</p>
<p>‚∏ª</p>
<p>üß™ 3. Permutation Importance</p>
<p>Using permutation importance, which measures the model‚Äôs drop in performance when features are shuffled, I again saw that trust, impact, and service were the most useful predictors. This aligns with what I saw in the correlation and regression results.</p>
<p>‚∏ª</p>
<p>üß† 4. Shapley Values (LMG Approximation)</p>
<p>Shapley value approximations confirmed the same pattern: trust and impact had the highest contributions to model R¬≤, while build and popular contributed very little.</p>
<p>‚∏ª</p>
<p>üìä 5. Johnson‚Äôs Relative Weights</p>
<p>This method really highlighted how dominant impact is ‚Äî it accounted for over 40% of the total explained variance. Trust (33%) and service (19%) followed. Features like rewarding and popular had near-zero weights, suggesting they don‚Äôt uniquely contribute much once everything else is accounted for.</p>
<p>‚∏ª</p>
<p>üå≥ 6. Random Forest Gini Importance</p>
<p>With Random Forest, I saw that trust, impact, and service were again top-ranked in terms of splitting power, confirming their importance in both linear and nonlinear models.</p>
<p>‚∏ª</p>
<p>‚úÖ Summary</p>
<p>Across all the methods I used, three features consistently emerged as the most important drivers of satisfaction: 1. Impact ‚Äì especially dominant in Johnson‚Äôs weights and regression. 2. Trust ‚Äì strong across all methods. 3. Service ‚Äì a reliable contributor in both linear and machine learning models.</p>
<p>Features like rewarding, build, and popular showed some association but had relatively minor unique contributions.</p>
<p>This analysis helped me identify not just what correlates with satisfaction, but which drivers have the strongest and most consistent predictive power across various modeling techniques.</p>
</section>
<section id="advanced-model-based-importance-measures-challenge" class="level3">
<h3 class="anchored" data-anchor-id="advanced-model-based-importance-measures-challenge">üß† Advanced Model-Based Importance Measures (Challenge)</h3>
<p>To deepen the analysis and explore the consistency of feature importance across modeling techniques, we extend the key drivers table with metrics from more advanced machine learning models. Specifically, we include permutation-based importance from a neural network and attempt to incorporate feature importance from XGBoost, a powerful gradient boosting framework. These models are capable of capturing complex, non-linear relationships that traditional regression may overlook. By comparing these modern importance metrics with earlier measures such as standardized coefficients and Gini importance, we can assess the robustness of our findings and uncover deeper insights into what truly drives customer satisfaction. This enhanced table provides a more holistic view, integrating classical statistical reasoning with modern machine learning interpretability.</p>
<div id="c836cd6f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPRegressor</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"other_docs/data_for_drivers_analysis.csv"</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Define features and target</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>features <span class="op">=</span> [<span class="st">'trust'</span>, <span class="st">'build'</span>, <span class="st">'differs'</span>, <span class="st">'easy'</span>, <span class="st">'appealing'</span>, <span class="st">'rewarding'</span>, <span class="st">'popular'</span>, <span class="st">'service'</span>, <span class="st">'impact'</span>]</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> <span class="st">'satisfaction'</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop missing values</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>df_clean <span class="op">=</span> df.dropna(subset<span class="op">=</span>features <span class="op">+</span> [target])</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_clean[features]</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_clean[target]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardize features</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Linear Regression (Standardized Coefficients)</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>linreg <span class="op">=</span> LinearRegression()</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>linreg.fit(X_scaled, y)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>std_coefficients <span class="op">=</span> pd.Series(linreg.coef_, index<span class="op">=</span>features)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Pearson Correlation</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>pearson_corr <span class="op">=</span> X.corrwith(y)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Random Forest for Gini importance</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>rf.fit(X, y)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>gini_importance <span class="op">=</span> pd.Series(rf.feature_importances_ <span class="op">*</span> <span class="dv">100</span>, index<span class="op">=</span>features)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Permutation Importance (Usefulness)</span></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>perm <span class="op">=</span> permutation_importance(rf, X, y, n_repeats<span class="op">=</span><span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>perm_importance <span class="op">=</span> pd.Series(perm.importances_mean <span class="op">*</span> <span class="dv">100</span>, index<span class="op">=</span>features)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a><span class="co"># --- LMG / Shapley Approximation (via Monte Carlo sampling)</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> approximate_lmg(X, y, num_samples<span class="op">=</span><span class="dv">200</span>):</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    var_names <span class="op">=</span> <span class="bu">list</span>(X.columns)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> <span class="bu">len</span>(var_names)</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    lmg_scores <span class="op">=</span> pd.Series(np.zeros(k), index<span class="op">=</span>var_names)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_samples):</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>        perm <span class="op">=</span> random.sample(var_names, k)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>        prev_X <span class="op">=</span> pd.DataFrame()</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>        prev_r2 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> var <span class="kw">in</span> perm:</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>            current_X <span class="op">=</span> pd.concat([prev_X, X[[var]]], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>            model <span class="op">=</span> LinearRegression().fit(current_X, y)</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>            new_r2 <span class="op">=</span> r2_score(y, model.predict(current_X))</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>            lmg_scores[var] <span class="op">+=</span> (new_r2 <span class="op">-</span> prev_r2)</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>            prev_X <span class="op">=</span> current_X</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>            prev_r2 <span class="op">=</span> new_r2</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>    lmg_scores <span class="op">/=</span> num_samples</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lmg_scores <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>lmg_approx <span class="op">=</span> approximate_lmg(X, y, num_samples<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Johnson's Relative Weights</span></span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> pca.fit_transform(X_scaled)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>eigenvalues <span class="op">=</span> pca.explained_variance_</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>loadings <span class="op">=</span> pca.components_.T</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> linreg.coef_</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> np.<span class="bu">sum</span>((loadings <span class="op">*</span> beta.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">**</span> <span class="dv">2</span> <span class="op">*</span> eigenvalues, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>rel_weights <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> weights <span class="op">/</span> np.<span class="bu">sum</span>(weights)</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>rel_weights_series <span class="op">=</span> pd.Series(rel_weights, index<span class="op">=</span>features)</span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Neural Network Permutation Importance</span></span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>mlp <span class="op">=</span> MLPRegressor(hidden_layer_sizes<span class="op">=</span>(<span class="dv">20</span>,), max_iter<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>mlp.fit(X_scaled, y)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>mlp_perm <span class="op">=</span> permutation_importance(mlp, X_scaled, y, n_repeats<span class="op">=</span><span class="dv">30</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>mlp_importance <span class="op">=</span> pd.Series(mlp_perm.importances_mean <span class="op">*</span> <span class="dv">100</span>, index<span class="op">=</span>features)</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Compile Results Table</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pearson Corr (%)"</span>: pearson_corr <span class="op">*</span> <span class="dv">100</span>,</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Std Coefficients (%)"</span>: std_coefficients <span class="op">*</span> <span class="dv">100</span>,</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Usefulness (Permutation) (%)"</span>: perm_importance,</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>    <span class="st">"LMG / Shapley (%)"</span>: lmg_approx,</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Johnson's Epsilon (%)"</span>: rel_weights_series,</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>    <span class="st">"RF Gini (%)"</span>: gini_importance,</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Neural Net Permutation (%)"</span>: mlp_importance</span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>}).<span class="bu">round</span>(<span class="dv">1</span>)</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Sort rows by overall importance (optional, e.g., by LMG or Pearson)</span></span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>results_sorted <span class="op">=</span> results.sort_values(by<span class="op">=</span><span class="st">"LMG / Shapley (%)"</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Style the table for better formatting</span></span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>styled_results <span class="op">=</span> results_sorted.style <span class="op">\</span></span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>    .background_gradient(cmap<span class="op">=</span><span class="st">'YlGnBu'</span>, axis<span class="op">=</span><span class="dv">0</span>) <span class="op">\</span></span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">format</span>(<span class="st">"</span><span class="sc">{:.1f}</span><span class="st">"</span>) <span class="op">\</span></span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>    .set_caption(<span class="st">"üîç Key Driver Importance Metrics (Multi-Model Comparison)"</span>) <span class="op">\</span></span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>    .set_properties(<span class="op">**</span>{<span class="st">"text-align"</span>: <span class="st">"center"</span>}) <span class="op">\</span></span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>    .set_table_styles([</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"selector"</span>: <span class="st">"th"</span>, <span class="st">"props"</span>: [(<span class="st">"text-align"</span>, <span class="st">"center"</span>)]},</span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"selector"</span>: <span class="st">"caption"</span>, <span class="st">"props"</span>: [(<span class="st">"caption-side"</span>, <span class="st">"top"</span>), (<span class="st">"font-weight"</span>, <span class="st">"bold"</span>), (<span class="st">"font-size"</span>, <span class="st">"14px"</span>)]}</span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Display the styled table</span></span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a>styled_results</span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a><span class="co"># Optional: save to CSV</span></span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a><span class="co"># results.to_csv("key_driver_importance_table.csv", index=True)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<style type="text/css">
#T_e56a8 th {
  text-align: center;
}
#T_e56a8 caption {
  caption-side: top;
  font-weight: bold;
  font-size: 14px;
}
#T_e56a8_row0_col0, #T_e56a8_row0_col2, #T_e56a8_row0_col3, #T_e56a8_row0_col5, #T_e56a8_row1_col1, #T_e56a8_row1_col3, #T_e56a8_row1_col4, #T_e56a8_row2_col6 {
  background-color: #081d58;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row0_col1 {
  background-color: #1e2e85;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row0_col4 {
  background-color: #23499e;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row0_col6, #T_e56a8_row1_col6 {
  background-color: #24419a;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row1_col0 {
  background-color: #0b1f5e;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row1_col2 {
  background-color: #2165ab;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row1_col5 {
  background-color: #2351a2;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row2_col0 {
  background-color: #162874;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row2_col1 {
  background-color: #1f7ab5;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row2_col2 {
  background-color: #216bae;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row2_col3 {
  background-color: #233390;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row2_col4 {
  background-color: #50bbc2;
  color: #000000;
  text-align: center;
}
#T_e56a8_row2_col5 {
  background-color: #1d90c0;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row3_col0 {
  background-color: #61c2bf;
  color: #000000;
  text-align: center;
}
#T_e56a8_row3_col1, #T_e56a8_row4_col3 {
  background-color: #cbebb4;
  color: #000000;
  text-align: center;
}
#T_e56a8_row3_col2 {
  background-color: #d9f0b3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row3_col3 {
  background-color: #aedfb6;
  color: #000000;
  text-align: center;
}
#T_e56a8_row3_col4 {
  background-color: #f5fbc4;
  color: #000000;
  text-align: center;
}
#T_e56a8_row3_col5, #T_e56a8_row5_col2, #T_e56a8_row6_col6, #T_e56a8_row7_col1, #T_e56a8_row7_col4, #T_e56a8_row7_col6, #T_e56a8_row8_col0, #T_e56a8_row8_col3 {
  background-color: #ffffd9;
  color: #000000;
  text-align: center;
}
#T_e56a8_row3_col6 {
  background-color: #299dc1;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row4_col0 {
  background-color: #44b7c4;
  color: #f1f1f1;
  text-align: center;
}
#T_e56a8_row4_col1 {
  background-color: #e9f7b1;
  color: #000000;
  text-align: center;
}
#T_e56a8_row4_col2 {
  background-color: #c6e9b4;
  color: #000000;
  text-align: center;
}
#T_e56a8_row4_col4 {
  background-color: #fcfed1;
  color: #000000;
  text-align: center;
}
#T_e56a8_row4_col5 {
  background-color: #d6efb3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row4_col6, #T_e56a8_row5_col5 {
  background-color: #f7fcc7;
  color: #000000;
  text-align: center;
}
#T_e56a8_row5_col0 {
  background-color: #e1f3b2;
  color: #000000;
  text-align: center;
}
#T_e56a8_row5_col1 {
  background-color: #dbf1b2;
  color: #000000;
  text-align: center;
}
#T_e56a8_row5_col3 {
  background-color: #ddf2b2;
  color: #000000;
  text-align: center;
}
#T_e56a8_row5_col4 {
  background-color: #f9fdcb;
  color: #000000;
  text-align: center;
}
#T_e56a8_row5_col6 {
  background-color: #eff9b6;
  color: #000000;
  text-align: center;
}
#T_e56a8_row6_col0 {
  background-color: #c8e9b4;
  color: #000000;
  text-align: center;
}
#T_e56a8_row6_col1, #T_e56a8_row6_col3, #T_e56a8_row7_col3 {
  background-color: #eef8b3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row6_col2 {
  background-color: #bde5b5;
  color: #000000;
  text-align: center;
}
#T_e56a8_row6_col4 {
  background-color: #fcfed3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row6_col5 {
  background-color: #ceecb3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row7_col0 {
  background-color: #b4e2b6;
  color: #000000;
  text-align: center;
}
#T_e56a8_row7_col2 {
  background-color: #d4eeb3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row7_col5 {
  background-color: #d3eeb3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row8_col1 {
  background-color: #f2fabc;
  color: #000000;
  text-align: center;
}
#T_e56a8_row8_col2 {
  background-color: #cfecb3;
  color: #000000;
  text-align: center;
}
#T_e56a8_row8_col4 {
  background-color: #fdfed5;
  color: #000000;
  text-align: center;
}
#T_e56a8_row8_col5 {
  background-color: #edf8b1;
  color: #000000;
  text-align: center;
}
#T_e56a8_row8_col6 {
  background-color: #87d0ba;
  color: #000000;
  text-align: center;
}
</style>

<div id="T_e56a8" class="quarto-float quarto-figure quarto-figure-center anchored" data-quarto-postprocess="true">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="T_e56a8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: üîç Key Driver Importance Metrics (Multi-Model Comparison)
</figcaption>
<div aria-describedby="T_e56a8-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table id="T_e56a8" class="caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="blank level0" data-quarto-table-cell-role="th">&nbsp;</th>
<th id="T_e56a8_level0_col0" class="col_heading level0 col0" data-quarto-table-cell-role="th">Pearson Corr (%)</th>
<th id="T_e56a8_level0_col1" class="col_heading level0 col1" data-quarto-table-cell-role="th">Std Coefficients (%)</th>
<th id="T_e56a8_level0_col2" class="col_heading level0 col2" data-quarto-table-cell-role="th">Usefulness (Permutation) (%)</th>
<th id="T_e56a8_level0_col3" class="col_heading level0 col3" data-quarto-table-cell-role="th">LMG / Shapley (%)</th>
<th id="T_e56a8_level0_col4" class="col_heading level0 col4" data-quarto-table-cell-role="th">Johnson's Epsilon (%)</th>
<th id="T_e56a8_level0_col5" class="col_heading level0 col5" data-quarto-table-cell-role="th">RF Gini (%)</th>
<th id="T_e56a8_level0_col6" class="col_heading level0 col6" data-quarto-table-cell-role="th">Neural Net Permutation (%)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_e56a8_level0_row0" class="row_heading level0 row0" data-quarto-table-cell-role="th">trust</td>
<td id="T_e56a8_row0_col0" class="data row0 col0">25.6</td>
<td id="T_e56a8_row0_col1" class="data row0 col1">13.6</td>
<td id="T_e56a8_row0_col2" class="data row0 col2">17.2</td>
<td id="T_e56a8_row0_col3" class="data row0 col3">2.2</td>
<td id="T_e56a8_row0_col4" class="data row0 col4">32.8</td>
<td id="T_e56a8_row0_col5" class="data row0 col5">15.6</td>
<td id="T_e56a8_row0_col6" class="data row0 col6">6.3</td>
</tr>
<tr class="even">
<td id="T_e56a8_level0_row1" class="row_heading level0 row1" data-quarto-table-cell-role="th">impact</td>
<td id="T_e56a8_row1_col0" class="data row1 col0">25.5</td>
<td id="T_e56a8_row1_col1" class="data row1 col1">15.0</td>
<td id="T_e56a8_row1_col2" class="data row1 col2">15.4</td>
<td id="T_e56a8_row1_col3" class="data row1 col3">2.2</td>
<td id="T_e56a8_row1_col4" class="data row1 col4">40.4</td>
<td id="T_e56a8_row1_col5" class="data row1 col5">14.1</td>
<td id="T_e56a8_row1_col6" class="data row1 col6">6.3</td>
</tr>
<tr class="odd">
<td id="T_e56a8_level0_row2" class="row_heading level0 row2" data-quarto-table-cell-role="th">service</td>
<td id="T_e56a8_row2_col0" class="data row2 col0">25.1</td>
<td id="T_e56a8_row2_col1" class="data row2 col1">10.4</td>
<td id="T_e56a8_row2_col2" class="data row2 col2">15.3</td>
<td id="T_e56a8_row2_col3" class="data row2 col3">2.0</td>
<td id="T_e56a8_row2_col4" class="data row2 col4">19.1</td>
<td id="T_e56a8_row2_col5" class="data row2 col5">13.0</td>
<td id="T_e56a8_row2_col6" class="data row2 col6">6.9</td>
</tr>
<tr class="even">
<td id="T_e56a8_level0_row3" class="row_heading level0 row3" data-quarto-table-cell-role="th">appealing</td>
<td id="T_e56a8_row3_col0" class="data row3 col0">20.8</td>
<td id="T_e56a8_row3_col1" class="data row3 col1">4.0</td>
<td id="T_e56a8_row3_col2" class="data row3 col2">11.8</td>
<td id="T_e56a8_row3_col3" class="data row3 col3">1.0</td>
<td id="T_e56a8_row3_col4" class="data row3 col4">2.8</td>
<td id="T_e56a8_row3_col5" class="data row3 col5">8.6</td>
<td id="T_e56a8_row3_col6" class="data row3 col6">5.4</td>
</tr>
<tr class="odd">
<td id="T_e56a8_level0_row4" class="row_heading level0 row4" data-quarto-table-cell-role="th">easy</td>
<td id="T_e56a8_row4_col0" class="data row4 col0">21.3</td>
<td id="T_e56a8_row4_col1" class="data row4 col1">2.6</td>
<td id="T_e56a8_row4_col2" class="data row4 col2">12.2</td>
<td id="T_e56a8_row4_col3" class="data row4 col3">0.9</td>
<td id="T_e56a8_row4_col4" class="data row4 col4">1.2</td>
<td id="T_e56a8_row4_col5" class="data row4 col5">10.0</td>
<td id="T_e56a8_row4_col6" class="data row4 col6">3.5</td>
</tr>
<tr class="even">
<td id="T_e56a8_level0_row5" class="row_heading level0 row5" data-quarto-table-cell-role="th">differs</td>
<td id="T_e56a8_row5_col0" class="data row5 col0">18.5</td>
<td id="T_e56a8_row5_col1" class="data row5 col1">3.3</td>
<td id="T_e56a8_row5_col2" class="data row5 col2">10.5</td>
<td id="T_e56a8_row5_col3" class="data row5 col3">0.8</td>
<td id="T_e56a8_row5_col4" class="data row5 col4">1.9</td>
<td id="T_e56a8_row5_col5" class="data row5 col5">9.0</td>
<td id="T_e56a8_row5_col6" class="data row5 col6">3.7</td>
</tr>
<tr class="odd">
<td id="T_e56a8_level0_row6" class="row_heading level0 row6" data-quarto-table-cell-role="th">build</td>
<td id="T_e56a8_row6_col0" class="data row6 col0">19.2</td>
<td id="T_e56a8_row6_col1" class="data row6 col1">2.3</td>
<td id="T_e56a8_row6_col2" class="data row6 col2">12.3</td>
<td id="T_e56a8_row6_col3" class="data row6 col3">0.7</td>
<td id="T_e56a8_row6_col4" class="data row6 col4">1.0</td>
<td id="T_e56a8_row6_col5" class="data row6 col5">10.2</td>
<td id="T_e56a8_row6_col6" class="data row6 col6">3.3</td>
</tr>
<tr class="even">
<td id="T_e56a8_level0_row7" class="row_heading level0 row7" data-quarto-table-cell-role="th">rewarding</td>
<td id="T_e56a8_row7_col0" class="data row7 col0">19.5</td>
<td id="T_e56a8_row7_col1" class="data row7 col1">0.6</td>
<td id="T_e56a8_row7_col2" class="data row7 col2">11.9</td>
<td id="T_e56a8_row7_col3" class="data row7 col3">0.7</td>
<td id="T_e56a8_row7_col4" class="data row7 col4">0.1</td>
<td id="T_e56a8_row7_col5" class="data row7 col5">10.1</td>
<td id="T_e56a8_row7_col6" class="data row7 col6">3.3</td>
</tr>
<tr class="odd">
<td id="T_e56a8_level0_row8" class="row_heading level0 row8" data-quarto-table-cell-role="th">popular</td>
<td id="T_e56a8_row8_col0" class="data row8 col0">17.1</td>
<td id="T_e56a8_row8_col1" class="data row8 col1">1.9</td>
<td id="T_e56a8_row8_col2" class="data row8 col2">12.0</td>
<td id="T_e56a8_row8_col3" class="data row8 col3">0.5</td>
<td id="T_e56a8_row8_col4" class="data row8 col4">0.7</td>
<td id="T_e56a8_row8_col5" class="data row8 col5">9.5</td>
<td id="T_e56a8_row8_col6" class="data row8 col6">4.6</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</div>
</div>
</section>
<section id="my-interpretation-of-the-driver-importance-table" class="level3">
<h3 class="anchored" data-anchor-id="my-interpretation-of-the-driver-importance-table">üß† My Interpretation of the Driver Importance Table</h3>
<p>To identify which features most influence customer satisfaction, I compared nine potential drivers using a variety of techniques. These included traditional statistical measures like Pearson correlation and standardized regression coefficients, as well as machine learning-based methods like permutation importance, Shapley value approximations (LMG), Johnson‚Äôs relative weights, Random Forest Gini importance, and Neural Net permutation scores. Here‚Äôs how I interpreted the results:</p>
<p>‚∏ª</p>
<p>üîπ 1. Pearson Correlation (%)</p>
<p>These values tell me how strongly each feature correlates with satisfaction on its own. I saw that: ‚Ä¢ Trust (25.6%), Impact (25.5%), and Service (25.1%) had the strongest linear relationships with satisfaction. ‚Ä¢ These three features are likely good standalone predictors.</p>
<p>‚∏ª</p>
<p>‚öôÔ∏è 2. Standardized Coefficients (%)</p>
<p>These reflect the effect of each feature in a multivariate linear regression model. Here: ‚Ä¢ Impact (15.0%) and Trust (13.6%) came out as top contributors, even after accounting for the presence of other features. ‚Ä¢ Service (10.4%) was also notably important. ‚Ä¢ Other variables like Rewarding, Popular, and Build had very low coefficients, which tells me they contribute relatively little when other variables are considered.</p>
<p>‚∏ª</p>
<p>üîÑ 3. Permutation Importance (%)</p>
<p>This model-agnostic approach shows how much predictive performance drops when a feature is randomly shuffled. ‚Ä¢ Again, Trust, Impact, and Service rank highest, reinforcing their central role. ‚Ä¢ Mid-tier features like Easy, Appealing, and Popular are still somewhat useful, but not dominant.</p>
<p>‚∏ª</p>
<p>üß† 4. LMG / Shapley Approximation (%)</p>
<p>LMG values estimate how much each variable contributes to explaining satisfaction, averaged across all possible feature orderings. ‚Ä¢ Impact (2.4%) and Trust (2.0%) had the largest shares of explanatory power. ‚Ä¢ Service (1.6%) remained consistently important. ‚Ä¢ Features like Popular and Differs had very low Shapley contributions, suggesting they don‚Äôt add much unique value.</p>
<p>‚∏ª</p>
<p>üìä 5. Johnson‚Äôs Relative Weights (%)</p>
<p>This method decomposes explained variance using PCA to isolate how much each variable contributes independently. ‚Ä¢ Impact (40.4%) and Trust (32.8%) absolutely dominated here. ‚Ä¢ Service (19.1%) also had significant weight. ‚Ä¢ Other features, especially Rewarding, Popular, and Build, had minimal impact‚Äîless than 3%.</p>
<p>‚∏ª</p>
<p>üå≥ 6. Random Forest Gini (%)</p>
<p>This measures how important each variable is for tree-based splits in the Random Forest model. ‚Ä¢ Again, Trust (15.6%), Impact (14.1%), and Service (13.0%) stood out. ‚Ä¢ Gini values were more evenly distributed across remaining features, but still consistent with the pattern.</p>
<p>‚∏ª</p>
<p>ü§ñ 7. Neural Net Permutation Importance (%)</p>
<p>This measures how much performance drops when features are shuffled in a trained neural network. ‚Ä¢ Service (6.9%), Impact (6.3%), and Trust (6.3%) were the top features. ‚Ä¢ Even here, nonlinear modeling confirms the dominance of the same three drivers.</p>
<p>‚∏ª</p>
<p>‚úÖ Final Summary</p>
<p>Across all seven methods, three features consistently emerged as the most important: 1. Impact ‚Äì Highest in regression, Johnson‚Äôs weights, and Shapley value. 2. Trust ‚Äì High across every metric. 3. Service ‚Äì Always near the top, including in neural networks and random forests.</p>
<p>Other features like Build, Rewarding, and Popular showed only minor influence. This analysis gives me strong confidence that Impact, Trust, and Service should be the key focus areas for improving customer satisfaction.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>