[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "My Projects",
    "section": "",
    "text": "Homework 1\n\ndabfliefqe;wd\n\n\nMario Nonog\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\nMario Nonog\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 3\n\n\n\n\nMario Nonog\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 4\n\n\n\n\nMario Nonog\nApr 23, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 5\n\n\n\n\nMario Nonog\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/hw1/hw1_questions.html",
    "href": "projects/hw1/hw1_questions.html",
    "title": "Homework 1",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn their 2007 paper published in the American Economic Review, Dean Karlan and John List explored the behavioral economics of charitable giving through a large-scale natural field experiment. They sought to answer a core question in fundraising strategy: Does the way a donation appeal is framed—particularly with the use of matching grants—significantly influence donor behavior? While prior research had focused heavily on tax incentives and the “supply side” of giving, Karlan and List shifted attention to the “demand side,” providing some of the first rigorous evidence on how potential donors respond to price-like mechanisms in real-world charitable campaigns.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#introduction",
    "href": "projects/hw1/hw1_questions.html#introduction",
    "title": "Homework 1",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn their 2007 paper published in the American Economic Review, Dean Karlan and John List explored the behavioral economics of charitable giving through a large-scale natural field experiment. They sought to answer a core question in fundraising strategy: Does the way a donation appeal is framed—particularly with the use of matching grants—significantly influence donor behavior? While prior research had focused heavily on tax incentives and the “supply side” of giving, Karlan and List shifted attention to the “demand side,” providing some of the first rigorous evidence on how potential donors respond to price-like mechanisms in real-world charitable campaigns.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#data",
    "href": "projects/hw1/hw1_questions.html#data",
    "title": "Homework 1",
    "section": "Data",
    "text": "Data\n\nDescription\nThe experiment was conducted in collaboration with a liberal nonprofit organization in the United States that focuses on civil liberties. The researchers utilized a direct mail fundraising campaign, sending letters to over 50,000 prior donors from the organization’s database. Each recipient received a four-page fundraising letter that was identical in content, except for three randomized elements in the treatment group.\nThe individuals were divided into:\nControl Group: Received a standard donation request letter, with no mention of a matching grant. Treatment Group: Received a letter including a paragraph that announced a matching grant from a “concerned fellow member.” Within the treatment group, letters were further randomized across three dimensions:\nMatch Ratio: $1:$1 (every dollar donated is matched with $1) $2:$1 (every dollar is matched with $2) $3:$1 (every dollar is matched with $3) Maximum Match Amount: $25,000, $50,000, $100,000, or left unstated Suggested Donation Amounts: Based on the recipient’s previous highest donation, the reply card listed either the same amount, 1.25×, or 1.5× that amount The match offer was framed both in the text of the letter and visually highlighted on the reply card included in the envelope. The control group’s reply card featured only the organization’s logo.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nIndex(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n       'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n       'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n       'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n       'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n       'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n       'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n       'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n       'pop_propurban'],\n      dtype='object')\n\nManual T-Test:\nDifference in means: 0.0137\nt-statistic: 0.1195\np-value: 0.9049\n\nLinear Regression Results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        14:57:51   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nGroup Means:\nTreatment mean: 13.01\nControl mean:   13.00\n\n\nThis result shows that there is no statistically significant difference in the variable mrm2 between the treatment and control groups. In fact, the difference is so small it’s essentially zero — people in both groups donated around 13 months ago, on average.\nThis is exactly what we expect and want before the experiment starts. It means the random assignment to treatment and control worked correctly — the two groups were similar before any fundraising letters were sent."
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#experimental-results",
    "href": "projects/hw1/hw1_questions.html#experimental-results",
    "title": "Homework 1",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\n\nimport pandas as pd\n# Generate random data\ndf = pd.read_stata('karlan_list_2007.dta')\nimport matplotlib.pyplot as plt\n\n# Calculate proportion who gave (1 = donated, 0 = didn't donate)\ndonation_rates = df.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\n# --- Plot ---\nplt.figure(figsize=(6, 5))\nplt.bar(labels, donation_rates, width=0.5)\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate by Group')\nplt.ylim(0, max(donation_rates) + 0.01)\nplt.grid(axis='y', linestyle='--', alpha=0.6)\n\n# Add values on top of bars\nfor i, val in enumerate(donation_rates):\n    plt.text(i, val + 0.001, f'{val:.2%}', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made (you can do this as a bivariate linear regression if you want). It may help to confirm your calculations match Table 2a Panel A. Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or something that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\n\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Split groups\ntreated = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\n\n# --- T-Test ---\nt_stat, p_value = stats.ttest_ind(treated, control, equal_var=False)\n\nprint(\"T-Test Results\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\n# --- Linear Regression ---\nmodel = smf.ols('gave ~ treatment', data=df).fit()\nprint(\"\\nLinear Regression Results:\")\nprint(model.summary())\n\nT-Test Results\nt-statistic: 3.2095\np-value: 0.0013\n\nLinear Regression Results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        14:57:51   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWhat This Means About Human Behavior We’ve learned that people are more likely to give when they know their donation will be matched. Even though the increase might seem small numerically, the effect is meaningful: simply mentioning a matching gift nudges more people into taking action.\nThis tells us that:\nSocial cues matter. When people know others are also giving (like a “concerned member” offering a match), it makes them feel part of something. Framing matters. The idea that their donation will “go further” encourages behavior change. Behavior is not purely rational — a simple sentence in a letter changes what people do with their money. This is why Table 2A (Panel A) in the paper is so important — it quantifies how a subtle psychological nudge leads to real-world donations.\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Run the probit model: gave ~ treatment\nprobit_model = smf.probit('gave ~ treatment', data=df).fit()\n\n# Print summary\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        14:57:51   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nNOTE: Linear regression results appear replicate Table 3 column 1 in the paper. Probit results do not, despite Table 3 indicating its results come from probit regressions…\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\nfrom scipy import stats\n\n# Filter treatment group only\nmatch_group = df[df['treatment'] == 1]\n\n# Define donation status for each ratio group\ngave_ratio_1 = match_group[match_group['ratio'] == 1]['gave']\ngave_ratio_2 = match_group[match_group['ratio'] == 2]['gave']\ngave_ratio_3 = match_group[match_group['ratio'] == 3]['gave']\n\n# --- 1:1 vs 2:1 ---\ntstat_1v2, pval_1v2 = stats.ttest_ind(gave_ratio_1, gave_ratio_2, equal_var=False)\nprint(\"T-test: 1:1 vs 2:1\")\nprint(f\"t-statistic = {tstat_1v2:.4f}, p-value = {pval_1v2:.4f}\")\n\n# --- 1:1 vs 3:1 ---\ntstat_1v3, pval_1v3 = stats.ttest_ind(gave_ratio_1, gave_ratio_3, equal_var=False)\nprint(\"\\nT-test: 1:1 vs 3:1\")\nprint(f\"t-statistic = {tstat_1v3:.4f}, p-value = {pval_1v3:.4f}\")\n\n# --- 2:1 vs 3:1 ---\ntstat_2v3, pval_2v3 = stats.ttest_ind(gave_ratio_2, gave_ratio_3, equal_var=False)\nprint(\"\\nT-test: 2:1 vs 3:1\")\nprint(f\"t-statistic = {tstat_2v3:.4f}, p-value = {pval_2v3:.4f}\")\n\nT-test: 1:1 vs 2:1\nt-statistic = -0.9650, p-value = 0.3345\n\nT-test: 1:1 vs 3:1\nt-statistic = -1.0150, p-value = 0.3101\n\nT-test: 2:1 vs 3:1\nt-statistic = -0.0501, p-value = 0.9600\n\n\n“While the match treatments relative to a control group increase the probability of donating, larger match ratios—$3:$1 and $2:$1—relative to a smaller match ratio ($1:$1) have no additional impact.”–from page 8\nYes — your results support the “figures suggest” comment made by the authors on page 8 of the Karlan & List (2007) paper. All p-values are well above 0.05, which means that none of the differences between match ratios are statistically significant. In other words, there’s no evidence that higher match ratios (like 2:1 or 3:1) increased the likelihood of giving compared to a 1:1 match.\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\n\n# 1. Filter for treatment group only (those who received a match offer)\nmatch_df = df[df['treatment'] == 1].copy()\n\n# 2. Create dummy variables for match ratio\nmatch_df['ratio1'] = (match_df['ratio'] == 1).astype(int)\nmatch_df['ratio2'] = (match_df['ratio'] == 2).astype(int)\nmatch_df['ratio3'] = (match_df['ratio'] == 3).astype(int)\n\n# 3. Regression using ratio2 and ratio3 (ratio1 is omitted and serves as baseline)\nmodel_dummies = smf.ols('gave ~ ratio2 + ratio3', data=match_df).fit()\nprint(\"Regression using dummy variables (baseline is ratio1):\\n\")\nprint(model_dummies.summary())\n\n# 4. Regression using ratio as categorical variable\nmodel_cat = smf.ols('gave ~ C(ratio)', data=match_df).fit()\nprint(\"\\nRegression using C(ratio) as a categorical variable:\\n\")\nprint(model_cat.summary())\n\nRegression using dummy variables (baseline is ratio1):\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.524\nTime:                        14:57:51   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nRegression using C(ratio) as a categorical variable:\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.4262\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.734\nTime:                        14:57:51   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33392   BIC:                        -3.333e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n=================================================================================\n                    coef    std err          t      P&gt;|t|      [0.025      0.975]\n---------------------------------------------------------------------------------\nIntercept      1.229e+09   1.12e+10      0.110      0.912   -2.07e+10    2.31e+10\nC(ratio)[T.1] -1.229e+09   1.12e+10     -0.110      0.912   -2.31e+10    2.07e+10\nC(ratio)[T.2] -1.229e+09   1.12e+10     -0.110      0.912   -2.31e+10    2.07e+10\nC(ratio)[T.3] -1.229e+09   1.12e+10     -0.110      0.912   -2.31e+10    2.07e+10\n==============================================================================\nOmnibus:                    38963.854   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506451.400\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                     3.21e+13\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 4.31e-23. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\n\nInterpretation: -People in the 1:1 match group donated at a rate of about 2.07%. -Offering a more generous match — 2:1 or 3:1 — slightly increased the donation rate by about 0.2 percentage points, but this difference was not statistically significant. -The p-values for both ratio2 and ratio3 are well above 0.05, meaning we cannot conclude that these match levels had a meaningful effect on donor behavior.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# Step 1: Filter to treatment group\nmatch_df = df[df['treatment'] == 1]\n\n# Step 2: Calculate response rates directly from data\nrate_1 = match_df[match_df['ratio'] == 1]['gave'].mean()\nrate_2 = match_df[match_df['ratio'] == 2]['gave'].mean()\nrate_3 = match_df[match_df['ratio'] == 3]['gave'].mean()\n\ndiff_1v2 = rate_2 - rate_1\ndiff_2v3 = rate_3 - rate_2\n\n# Step 3: Use regression coefficients (from earlier model)\n# These should match your actual model output — adjust if needed\nrate_1_pred = 0.0207        # Intercept\ncoef_ratio2 = 0.0019\ncoef_ratio3 = 0.0020\n\nrate_2_pred = rate_1_pred + coef_ratio2\nrate_3_pred = rate_1_pred + coef_ratio3\n\ndiff_1v2_pred = rate_2_pred - rate_1_pred\ndiff_2v3_pred = rate_3_pred - rate_2_pred\n\n# Step 4: Display results\nprint(\"🔢 Direct from data:\")\nprint(f\"Response rate (1:1): {rate_1:.4f}\")\nprint(f\"Response rate (2:1): {rate_2:.4f}\")\nprint(f\"Response rate (3:1): {rate_3:.4f}\")\nprint(f\"1:1 vs 2:1 match difference: {diff_1v2:.4f}\")\nprint(f\"2:1 vs 3:1 match difference: {diff_2v3:.4f}\")\n\nprint(\"\\n📊 From regression coefficients:\")\nprint(f\"Predicted rate (1:1): {rate_1_pred:.4f}\")\nprint(f\"Predicted rate (2:1): {rate_2_pred:.4f}\")\nprint(f\"Predicted rate (3:1): {rate_3_pred:.4f}\")\nprint(f\"1:1 vs 2:1 match difference (predicted): {diff_1v2_pred:.4f}\")\nprint(f\"2:1 vs 3:1 match difference (predicted): {diff_2v3_pred:.4f}\")\n\n🔢 Direct from data:\nResponse rate (1:1): 0.0207\nResponse rate (2:1): 0.0226\nResponse rate (3:1): 0.0227\n1:1 vs 2:1 match difference: 0.0019\n2:1 vs 3:1 match difference: 0.0001\n\n📊 From regression coefficients:\nPredicted rate (1:1): 0.0207\nPredicted rate (2:1): 0.0226\nPredicted rate (3:1): 0.0227\n1:1 vs 2:1 match difference (predicted): 0.0019\n2:1 vs 3:1 match difference (predicted): 0.0001\n\n\nFrom both your raw data and regression predictions, here’s what we can conclude:\n-Moving from a 1:1 to a 2:1 match increases the donation rate by just 0.19 percentage points. -Moving from a 2:1 to a 3:1 match increases the rate by only 0.01 percentage points. -These changes are extremely small and, as your earlier t-tests and regression showed, not statistically significant.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\n\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Step 1: Split into treatment and control groups\namount_treat = df[df['treatment'] == 1]['amount']\namount_control = df[df['treatment'] == 0]['amount']\n\n# Step 2: T-test\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_control, equal_var=False)\n\nprint(\"🔢 T-Test: Donation Amount by Treatment\")\nprint(f\"Treatment mean: {amount_treat.mean():.2f}\")\nprint(f\"Control mean:   {amount_control.mean():.2f}\")\nprint(f\"Difference:     {(amount_treat.mean() - amount_control.mean()):.2f}\")\nprint(f\"t-statistic:    {t_stat:.4f}\")\nprint(f\"p-value:        {p_val:.4f}\")\n\n# Step 3: Regression\nmodel = smf.ols('amount ~ treatment', data=df).fit()\nprint(\"\\n📊 Linear Regression Results:\")\nprint(model.summary())\n\n🔢 T-Test: Donation Amount by Treatment\nTreatment mean: 0.97\nControl mean:   0.81\nDifference:     0.15\nt-statistic:    1.9183\np-value:        0.0551\n\n📊 Linear Regression Results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        14:57:51   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n-This analysis shows that offering a match might increase not only the likelihood of giving but also the amount given, though the evidence is not quite strong enough to be statistically conclusive at the standard 95% confidence level.\n-So far, the match offer seems to mainly help on the extensive margin — getting more people to donate. Its effect on the intensive margin — how much people give — appears small and uncertain.\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\n\n# Filter to donors only (people who gave)\ndonors_df = df[df['gave'] == 1]\n\n# T-test: Did treatment group donors give more than control group donors?\namount_treat = donors_df[donors_df['treatment'] == 1]['amount']\namount_control = donors_df[donors_df['treatment'] == 0]['amount']\n\n# T-test\nfrom scipy import stats\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_control, equal_var=False)\n\nprint(\"🔢 T-Test: Donation Amount (Conditional on Giving)\")\nprint(f\"Treatment mean: {amount_treat.mean():.2f}\")\nprint(f\"Control mean:   {amount_control.mean():.2f}\")\nprint(f\"Difference:     {(amount_treat.mean() - amount_control.mean()):.2f}\")\nprint(f\"t-statistic:    {t_stat:.4f}\")\nprint(f\"p-value:        {p_val:.4f}\")\n\n# Regression: amount ~ treatment (only among donors)\nimport statsmodels.formula.api as smf\nmodel = smf.ols('amount ~ treatment', data=donors_df).fit()\n\nprint(\"\\n📊 Linear Regression (Among Donors Only):\")\nprint(model.summary())\n\n🔢 T-Test: Donation Amount (Conditional on Giving)\nTreatment mean: 43.87\nControl mean:   45.54\nDifference:     -1.67\nt-statistic:    -0.5846\np-value:        0.5590\n\n📊 Linear Regression (Among Donors Only):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        14:57:51   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nWhat does the regression coefficient on treatment tell us? Answer: The coefficient on treatment is –1.67, which means that, among those who donated, people in the treatment group gave $1.67 less on average than those in the control group. However, the p-value is 0.561, indicating that this difference is not statistically significant. In short, we find no evidence that the treatment affected the amount donated among those who gave.\nWhat did we learn from this analysis? Answer: We learned that the matching grant offer did not change how much people gave, once they decided to donate. The main impact of the treatment was likely on getting people to donate in the first place (the extensive margin), not on how much they donated (the intensive margin). So the match was effective at increasing participation, but not effective at increasing donation size among participants.\nDoes the treatment coefficient have a causal interpretation? Answer: No, the treatment coefficient in this regression does not have a valid causal interpretation.\nWhy not? Because the regression is conditional on donating (i.e., only includes people for whom gave == 1). But treatment itself influences who ends up in this group — meaning we’re analyzing a selected subgroup that may differ systematically between treatment and control.\nThis introduces selection bias, so the regression tells us about differences among donors, but not about the causal effect of treatment on donation size.\ntodo: Make two plots: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\nimport matplotlib.pyplot as plt\n\n# Filter to only people who donated\ndonors_df = df[df['gave'] == 1]\n\n# Split treatment and control groups\ndonors_treat = donors_df[donors_df['treatment'] == 1]['amount']\ndonors_control = donors_df[donors_df['treatment'] == 0]['amount']\n\n# Calculate group means\nmean_treat = donors_treat.mean()\nmean_control = donors_control.mean()\n\n# Create side-by-side plots\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Treatment group histogram\naxes[0].hist(donors_treat, bins=30, color='skyblue', edgecolor='black')\naxes[0].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: ${mean_treat:.2f}')\naxes[0].set_title('Treatment Group')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\n# Control group histogram\naxes[1].hist(donors_control, bins=30, color='lightgreen', edgecolor='black')\naxes[1].axvline(mean_control, color='red', linestyle='--', label=f'Mean: ${mean_control:.2f}')\naxes[1].set_title('Control Group')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.suptitle('Donation Amounts Among Donors')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/hw1/hw1_questions.html#simulation-experiment",
    "href": "projects/hw1/hw1_questions.html#simulation-experiment",
    "title": "Homework 1",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. This average will likely be “noisey” when only averaging a few numbers, but should “settle down” and approximate the treatment effect (0.004 = 0.022 - 0.018) as the sample size gets large. Explain the chart to the reader.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Step 1: Get actual response rates\np_control = df[df['treatment'] == 0]['gave'].mean()  # ≈ 0.018\np_treat = df[df['treatment'] == 1]['gave'].mean()    # ≈ 0.022\ntrue_effect = p_treat - p_control                    # Should be ≈ 0.004\n\n# Step 2: Simulate 10,000 Bernoulli draws for each group\nnp.random.seed(42)  # For reproducibility\nn = 10000\ncontrol_sim = np.random.binomial(1, p_control, n)\ntreat_sim = np.random.binomial(1, p_treat, n)\n\n# Step 3: Calculate difference in outcomes\ndiffs = treat_sim - control_sim  # Vector of 10,000 differences\n\n# Step 4: Calculate cumulative average of differences\ncum_avg_diff = np.cumsum(diffs) / np.arange(1, n + 1)\n\n# Step 5: Plot the cumulative average\nplt.figure(figsize=(10, 5))\nplt.plot(cum_avg_diff, label='Cumulative Average of Differences')\nplt.axhline(y=true_effect, color='red', linestyle='--', label=f'Estimated Treatment Effect ≈ {true_effect:.4f}')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Treatment Effect')\nplt.title('Simulation: Convergence Toward Treatment Effect')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n-At first (left side of the plot), the estimate is highly volatile — bouncing around because it’s based on only a few observations. -As the number of simulations increases (moving right), the average stabilizes and converges to the true treatment effect. -This is a practical demonstration of the Law of Large Numbers: the more data we gather, the more reliable our estimate becomes.\n\n\nCentral Limit Theorem\nAs the number of simulations increases (moving right), the average stabilizes and converges to the true treatment effect. This is a practical demonstration of the Law of Large Numbers: the more data we gather, the more reliable our estimate becomes.\nto do: Make 4 histograms at sample sizes 50, 200, 500, and 1000. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. The repeat for the other 3 histograms. Explain this sequence of histograms and its relationship to the central limit theorem to the reader.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Step 1: Define control and treatment probabilities\np_control = df[df['treatment'] == 0]['gave'].mean()\np_treat = df[df['treatment'] == 1]['gave'].mean()\n\n# Step 2: Function to simulate sampling and compute mean differences\ndef simulate_differences(sample_size, n_reps=1000):\n    diffs = []\n    for _ in range(n_reps):\n        control_draw = np.random.binomial(1, p_control, sample_size)\n        treat_draw = np.random.binomial(1, p_treat, sample_size)\n        diff = treat_draw.mean() - control_draw.mean()\n        diffs.append(diff)\n    return diffs\n\n# Step 3: Run simulations for different sample sizes\nsizes = [50, 200, 500, 1000]\nsim_results = {n: simulate_differences(n) for n in sizes}\n\n# Step 4: Plot histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sizes):\n    axes[i].hist(sim_results[n], bins=30, color='lightblue', edgecolor='black')\n    axes[i].axvline(x=np.mean(sim_results[n]), color='red', linestyle='--', label=f\"Mean ≈ {np.mean(sim_results[n]):.4f}\")\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Mean Difference (Treatment - Control)\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.suptitle(\"Histograms of Simulated Treatment Effects at Varying Sample Sizes\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n-Sample Size = 50: The distribution is wide and erratic. The sample mean differences vary a lot — some simulations overestimate the effect, others underestimate it. The shape is not very normal.\n-Sample Size = 200: The distribution begins to tighten. It’s more centered around the true effect, though still somewhat spread out.\n-Sample Size = 500: The distribution is clearly bell-shaped, centered around the estimated effect, with less variation.\n-Sample Size = 1000: The distribution is even tighter and smoother. Most estimates fall within a narrow range around the true effect of ~0.0045."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Mario’s Resume",
    "section": "",
    "text": "last updated 2025-04-05\nDownload PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mario P. Nonog Jr.",
    "section": "",
    "text": "Navy Veteran Officer and Business Analyst Graduate Student with expertise in Statistical Forecasting, Planning and technical data expertise. Skilled in Mathematical Instrument such as python (pandas, numpy), MATLAB, and Excel to deliver insights, statistical models, and solutions of complex problems through integration and regression testing."
  }
]