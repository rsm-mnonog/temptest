---
title: "TZ Gaming: Optimal Targeting of Mobile Ads"
description: "Logistic Regression, Permutation Importance, Prediction Plots, Pseudo R-Squared, Chi-Square Test, Correlation, Decile Analysis, Gain Curves, Confusion Matrix"
author: "Mario Nonog"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
theme: cosmo
image: "other_docs/HW_PHOTO.jpg"
---

### Problem Description:
As a developer of games for mobile devices, TZ gaming has achieved strong growth of its customer base. A
prominent source of new customers has come from ads displayed through the Vneta ad-network. A mobile-ad
network is a technology platform that serves as a broker between (1) app developers (or publishers) looking
to sell ad space and (2) a group of advertisers.

App developers sell “impressions”, i.e., a space where an ad can be shown, through the Vneta network to
companies such as TZ gaming looking to advertise to app users. Vneta acts as a broker for 50-60 millions
impressions/ads per day.
TZ gaming uses ads to appeal to prospective customers for their games. They generally use short (15
sec) video ads that help to emphasize the dynamic nature of the games. In the past, TZ has been able
to, approximately, break-even on ad-spend with Vneta when calculating the benefits that can be directly
attributed to ad click-through. Many senior executives at TZ believe that there are additional, longer-term,
benefits from these ads such as brand awareness, etc. that are harder to quantify.

Currently, TZ has access to very limited data from Vneta. Matt Huateng, the CEO of TZ gaming, is
intrigued by the potential for data science to enhance the efficiency of targeted advertising on mobile devices.
Specifically, two options are under consideration: (1) Buy access to additional data from Vneta and use TZ’s
analytics team to build targeting models or (2) Subscribe to Vneta’s analytics consultancy service, which
provides impression-level click-through rate predictions based on Vneta’s proprietary data and algorithms.

Vneta has shared behavioral information linked to 115,488 recent impressions used to show TZ ads and has
also provided a set or predictions based on their own (proprietary) algorithm. Matt is unsure if the consulting
services offered by Vneta will be worth the money for future ad campaigns and has asked you to do some
initial analyses on the provided data and compare the generated predictions to Vneta’s recommendations.
The following targeting options will be evaluated to determine the best path forward.

### Options:
1. Spam all prospects
2. Continue with the current targeting approach
3. Use predictions from a logistic regression model for ad targeting
4. Use predictions generated by Vneta for ad targeting


### Assumptions
The assumptions used for the analysis are as follows:
• Targeting of impressions to consumers covered by the Vneta ad-network to date has been (approximately) random
• Cost per 1,000 video impressions (CPM) is $10
• Conversion to sign-up as a TZ game player after clicking on an ad is 5%
• The expected CLV of customers that sign-up with TZ after clicking on an ad is approximately $25
• The price charged for the data by Vneta is $50K
• The price charged for the data science consulting services by Vneta is $150K

### Approach:
• Use the 87,535 rows in the data with “training == ‘train’ ” to estimate different models. Then generate
predictions for all 115,488 rows in the dataset
• Options 1-4 should be evaluated only on the predictions generated for the 27,953 rows in the data with
“training == ‘test’ ”. These are the observations that were not used to estimate your model
• Extrapolate the cost and benefits for options 1-4 above for an upcoming advertising campaign where
TZ will commit to purchase 20-million impressions from Vneta

TZ gaming has decided to use logistic regression for targeting. This is a powerful and widely used tool to
model consumer response. It is similar to linear regression but the key difference is that the response variable
(target) is binary (e.g., click or no-click) rather than continuous. For each impression, the logistic regression
model will predict the probability of click-through, which can be used for ad targeting. Like linear regression,
you can include both continuous and categorical predictors in your model as explanatory variables (features).
Matt is eager to assess the value of logistic regression as a method to predict ad click-through and target
prospects and has asked you to complete the following analyses.

### TZ Gaming: Optimal Targeting of Mobile Ads

Each row in the `tz_gaming` dataset represents an impression. For each row (impression), we have data on 21 variables. All explanatory variables are created by Vneta based on one month tracking history of users, apps, and ads. The available variables are described in below. 

* _training_ -- Dummy variable that splits the dataset into a training ("train") and a test ("test") set
* _inum_ -- Impression number
* _click_ -- Click indicator for the TZ ad served in the impression. Equals "yes" if the ad was clicked and "no" otherwise
* _time_ -- The hour of the day in which the impression occurred (1-24). For example, "2" indicates the impression occurred between 1 am and 2 am
* _time\_fct_ -- Same as _time_ but the is coded as categorical 
* _app_ -- The app in which the impression was shown. Ranges from 1 to 49
* _mobile\_os_ -- Customer's mobile OS
* _impup_ -- Number of past impressions the user has seen in the app
* _clup_ -- Number of past impressions the user has clicked on in the app
* _ctrup_ -- Past CTR (Click-Through Rate) (x 100) for the user in the app
* _impua_ -- Number of past impressions of the TZ ad that the user has seen across all apps
* _clua_ -- Number of past impressions of the TZ ad that the user has clicked on across all apps
* _ctrua_ -- Past CTR (x 100) of the TZ ad by the user across all apps
* _imput_ -- Number of past impressions the user has seen within in the hour
* _clut_ -- Number of past impressions the user has clicked on in the hour
* _ctrut_ -- Past CTR (x 100) of the user in the hour
* _imppat_ -- Number of past impressions that showed the TZ ad in the app in the hour
* _clpat_ -- Number of past clicks the TZ ad has received in the app in the hour
* _ctrpat_ -- Past CTR (x 100) of the TZ ad in the app in the hour
* _rnd_ -- Simulated data from a normal distribution with mean 0 and a standard deviation of 1
* _pred\_vneta_ -- Predicted probability of click per impressions generated by Vneta's proprietary machine learning algorithm
* id -- Anonymized user ID

Note that there is a clear relationship between the impressions, clicks, and ctr variables within a strata. Specifically: 

* ctrup = clup/impup
* ctru = clu/impu
* ctrut = clut/imput
* ctrpat = clpat/impat

The last three letters of a feature indicate the sources of variation in a variable:

* u — denotes user
* t — denotes time
* p — denotes app
* a — denotes ad 

### Logistic Regression
:::: {.callout-note collapse="true"}

```{python}
import pandas as pd
tz_gaming = pd.read_parquet("data/tz_gaming.parquet")
print(tz_gaming)
```

```{python}
tz_train = tz_gaming[tz_gaming["training"] == "train"]
print(tz_train["training"].head())

tz_train
```
::::

```{python}
import pyrsm as rsm
clf= rsm.model.logistic(
        data={"tz_train":tz_train},
        rvar= "click",
        lev="yes",
        evar=[ "time_fct", "app", "mobile_os", "impua", "clua", "ctrua"]
)
clf.summary()
```

### Interpretation
For OR (Odds Ratio) As another hour is added to tim_fct[2], the model suggest that the odds of clicking will decrease by a factor of 0.622 or by 37.8% that is when keeping all other variable in the model constant. 

For OR (Odds Ratio) As another hour is added to tim_fct[3], the model suggest that the odds of clicking will decrease by a factor of 0.718 or by 28.2% that is when keeping all other variable in the model constant. 

And so on for all the rest of the features. 

### Chi-Square Citical Value

```{python}
from scipy.stats import chi2
df=76
alpha_0_05 = chi2.ppf(1-0.05,df)
alpha_0_01= chi2.ppf(1-0.01,df)
print(alpha_0_05,alpha_0_01)
```

The logistic regression chi square value (970) is so much higher than both the calculated chi-square critical value above(97, 107). Therefore, the difference between the observed data and expected data is extremely large, thus reject the null hypothesis. 

:::: {.callout-note collapse="true"}
### Model Fit Metrics

| Metric             | Value |Meaning                                                         |
|----------------------|---------------------------------------------------------------------|
| McFadden Pseudo R²   | 0.109,  Indicates modest model fit (0.2–0.4 is strong)                                                          |
| Adjusted Pseudo R²   |  0.092, Slightly adjusted down for number of predictors                                                                 
| AUC             | 0.792, 	Good discrimination power (0.7–0.8 = good)                                                    |
| Log-likelihood           | -3946.072  higher is better                                                  
| AIC              | 8046.145, Lower = better fit                                                   |
| BIC        | 8768.389, Penalizes complexity more than AIC                                        |
| Chi-squared (df=76)           | 968.279, Strong model signal (p < 0.001)                                        |
| Number of Observations         |87,535,Large dataset, good statistical power 
::::

Based on the p=value the most significant features are app2. app13, app14, mobile_os, impua,clua and ctrua. Now let use a different method to see the variable that is the  most important. However, first let us see the plot of the classifier (clf)

### Plot

```{python}
clf.plot(
    plots="pred", incl=[ "time_fct", "app", "mobile_os", "impua", "clua", "ctrua"]
)
```

### Permutation Importance

```{python}
clf.plot("vimp")
```

### Interpretation

The app variable has the highest importance because it has the highest decrease in AUC after permutted. Impua comes second which still contributes significantly on model predictions. Then, mobile_os is next important and the last three is time_fct, clua, ctrua have way less impact on model predictions. The chi square of 968 is way above our critical value of 97 and 107, which means that there is a greater deviation between observed and expected frequencies, suggesting that more variables are more likely to be dependent or assoicated from each other, which is also supported by  the p_value less than 0.001. The Pseudo R-Squared of 0.109 or 0.092 when adjusted indicates the goodness of fit for logistic regression, higher means better fit. This number shows on how well the independent variales explain the dependent variables. 



### Prediction of Click Probability

```{python}
tz_gaming["pred_logit"]= clf.predict(tz_gaming)["prediction"]
print(tz_gaming.head())

```
```{python}
tz_train["pred_logit"]= clf.predict(tz_train)["prediction"]
print(tz_train.head())

```


### Logistic Regression (EVAR: ONLY RND)
```{python}
clf_rnd= rsm.model.logistic(
    data= {"tz_train": tz_train},
    rvar= "click",
    lev= "yes",
    evar= "rnd"
)
clf_rnd.summary()
```

### Prediction of Click Probability (EVAR: ONLY RND)

```{python}
tz_gaming["pred_rnd"]= clf_rnd.predict(tz_gaming)["prediction"]
print(tz_gaming.head())

```
```{python}
tz_train["pred_rnd"]= clf_rnd.predict(tz_train)["prediction"]
print(tz_train.head())

```

## Multicollinearity and Omitted Variable Bias

``` {python}
clf_mc1 = rsm.model.logistic(
    data= {"tz_train":tz_train},
    rvar= "click",
    lev= "yes",
    evar= ["imppat", "clpat", "ctrpat"]
)
clf_mc1.summary()
```

### Chi-Square Citical Value

```{python}
from scipy.stats import chi2
df=3
alpha_0_05 = chi2.ppf(1-0.05,df)
alpha_0_01= chi2.ppf(1-0.01,df)
print(alpha_0_05,alpha_0_01)
```

### Plot
``` {python}
clf_mc1.plot(
    plots="pred", incl=["imppat", "clpat", "ctrpat"]
)
```

### Permutation Importance
```{python}
clf_mc1.plot(plots="vimp")
```

### Interpretation

For Odd Ratio, when you increase the ctrpat (click throgh put rate) by one unit, the odds of the outcome which is clicking increases by a factor of 1.615 or 61.5% while other variables remain constant.Meanwhile, a unit increase only by a factor of 1.002 for clpt (past clicks in a specific hour) and no effect on odd of clicking for the feature imppat (the number of past impression that showed a TZ ad)

Using the coefficient and the plot, an increase in the number of past impression that showed a TZ ad(immpat) has a insignificant negative correlation(-0.00) with odds of clicking. This shows in both regression and plot. Then, there is a slight positive coeffecient(0.00) between clpat and the odds of clicking. Finally, we have considerable positive correlation(0.48) between ctrpat and the odds of clicking. Both of these shows in the plot as well. 

 all p_values are less than 0.05 implies on the significant effect of imppat, ctrpat and clpat on the odds of clicking. In fact, they all have three asterisk which amplifies the level of statistical significance of these three variables.

#### Correlation

```{python}

tz_train[['imppat', 'clpat', 'ctrpat']].corr()

```
``` {python}
clf_mc2 = rsm.model.logistic(
    data= {"tz_train": tz_train},
    rvar = "click",
    lev= "yes",
    evar =["imppat", "ctrpat"],
 )
clf_mc2.summary()
```

``` {python}
clf_mc2.plot("pred")
```

#### Interpretation

The coefficient of ctrpat increased from 0.48 to 0.55, and the odds ratio rose from 61.5% to 73.3%. This suggests that removing clpat revealed the true impact of the remaining explanatory variables. While Pseudo R-Squared and AUC were not significantly affected, the predicted plot now shows a clearer relationship between the odds of clicking and the variables imppat and ctrpat. Since imppat and clpat have a high correlation of 0.97, multicollinearity exists, which can make coefficient estimates unstable and affect model interpretation. By omitting one of these highly correlated variables, we mitigate this issue, leading to a more interpretable model. This is evident in the plot, where the relationship between ctrpat, imppat, and the odds of clicking is now more clearly observed.

#### Difference After Adding More Features
``` {python}
clf_mc3 = rsm.model.logistic (
    data = {"tz_train": tz_train},
    rvar= "click",
    lev= "yes",
    evar=["time_fct", "app", "imppat", "clpat", "ctrpat"]
)

clf_mc3.summary()

```

``` {python}
clf_mc3.plot(
    plots="pred", incl=["time_fct", "app", "imppat", "clpat", "ctrpat"]
)
```

#### Interpretation
Introducing variables like time_fct and app into a logistic regression model with imppat, clpat, and ctrpat can alter prediction plots by changing the relationships between predictors and the outcome. These new variables may interact with existing ones, influencing both the direction and magnitude of effects. Additionally, they can act as confounder adjustments, revealing the true impact of imppat, clpat, and ctrpat on click likelihood by accounting for hidden biases. Conditioning effects may also emerge, as the behavior of existing predictors shifts in the presence of time_fct and app, leading to different probability estimates. Ultimately, these changes are reflected in prediction plots, which visually capture the refined relationships between predictors and the outcome, offering a clearer interpretation of the model's dynamics.

### Decile Analysis
```{python}
tz_test =tz_gaming[tz_gaming["training"] == "test"]
tz_test["pred_logit_dec"] = (tz_test.groupby("training").pred_logit.transform(rsm.xtile, 10, rev=True))
print(tz_test.head())
```

``` {python}
dec_tab = (
    tz_test.groupby('pred_logit_dec')
    .agg(
        nr_impressions= ("pred_logit_dec", "size"),
        nr_clicks= ("click", lambda x: (x == "yes").sum()),
    )
    .assign( ctr= lambda x: x.nr_clicks / x.nr_impressions)
    .reset_index()
)
dec_tab
```

#### Bar Chart
```{python}
import matplotlib.pyplot as plt
bc= dec_tab.plot.bar(x="pred_logit_dec", y="ctr", legend=False)

bc.set_xlabel('Decile')
bc.set_ylabel ("click through rate (CTR)")
bc.set_title ("Click Through Rate by Decile")
bc.axhline(dec_tab["ctr"].mean(), color='r', linestyle='--')

plt.show()
print(tz_train)
```


### Gain Curves

```{python}
dec_tab["cum_prop"]= dec_tab["nr_impressions"].cumsum()/dec_tab["nr_impressions"].sum()
dec_tab["cum_gains"]= dec_tab['nr_clicks'].cumsum()/dec_tab['nr_clicks'].sum()
gains_tab = dec_tab
gains_tab

```

```{python}
plt.figure(figsize=(10, 6))
plt.plot(dec_tab['cum_prop'], dec_tab['cum_gains'], label='Cumulative Gains', drawstyle='steps-post')
plt.plot([0, 1], [0, 1], 'k--', label='No Model')  

# Labeling the plot
plt.title('Cumulative Gains Chart')
plt.xlabel('Cumulative Proportion of Impressions')
plt.ylabel('Cumulative Gains')
plt.legend()
plt.grid(True)

# Show the plot
plt.show()
```

### Confusion Matrix

```{python}
cpm = 10 # cost per 1000 video impression
conversion_rate= 0.05   # conversion to sign up with TZ after clicking on an ad
clv= 25 # expected clv of customers that sign up with TZ after clicking on an ad

threshold= (cpm/(conversion_rate * clv *1000))
threshold
```

```{python}
tz_test = tz_gaming[tz_gaming["training"] == "test"].copy()

tz_test["click_yes"]= tz_test["click"].apply(lambda x: 1 if x == "yes" else 0 if x == "no" else np.nan)

tz_test["click_yes"] = tz_test["click_yes"].astype(float)


tz_test
```

```{python}
TP = ((tz_test["training"] == "test") & (tz_test["pred_logit"]> threshold) & (tz_test["click_yes"] == 1)).sum()
FP = ((tz_test["training"] == "test") & (tz_test["pred_logit"]> threshold) & (tz_test["click_yes"] == 0)).sum()
TN = ((tz_test["training"] == "test") & (tz_test["pred_logit"]<= threshold) & (tz_test["click_yes"] == 0)).sum()
FN = ((tz_test["training"] == "test") & (tz_test["pred_logit"]<= threshold) & (tz_test["click_yes"] == 1)).sum()

cm_logit = pd.DataFrame(
    {
        "label": ["TP", "FP", "TN", "FN"],
        "nr" : [TP, FP, TN, FN]# TP, FP, TN, and FN values in that order
    }
)
cm_logit

```

#### Accuracy
```{python}
accuracy_logit = (TP + TN) / (TP + TN + FP + FN)# float
accuracy_logit
```

#### Confusion Matrix Based on Pred_RND

```{python}

TP = ((tz_test["training"] == "test") & (tz_test["pred_rnd"]> threshold) & (tz_test["click_yes"] == 1)).sum()
FP = ((tz_test["training"] == "test") & (tz_test["pred_rnd"]> threshold) & (tz_test["click_yes"] == 0)).sum()
TN = ((tz_test["training"] == "test") & (tz_test["pred_rnd"]<= threshold) & (tz_test["click_yes"] == 0)).sum()
FN = ((tz_test["training"] == "test") & (tz_test["pred_rnd"]<= threshold) & (tz_test["click_yes"] == 1)).sum()


cm_rnd = pd.DataFrame(
    {
        "label": ["TP", "FP", "TN", "FN"],
        "nr": [TP, FP, TN, FN]# TP, FP, TN, and FN values in that order
    }
)
cm_rnd
```

### Accuracy Based on Pred_RND Confusion Matrix
``` {python}
accuracy_rnd = (TP + TN) / (TP + TN + FP + FN)# float
accuracy_rnd

```

#### Summary and Interpretation

``` {python}
first_model = {
    "TP": 271,
    "FP": 27606,
    "TN": 76,
    "FN": 0
}

rnd_model = {
    "TP": 0,
    "FP": 0,
    "TN": 27682,
    "FN": 271
}

def compute_metrics(cm):
    TP = cm["TP"]
    FP = cm["FP"]
    TN = cm["TN"]
    FN = cm["FN"]
    total = TP + FP + TN + FN

    accuracy = (TP + TN) / total
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0
    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return {
        "TP": TP,
        "FP": FP,
        "TN": TN,
        "FN": FN,
        "Accuracy": round(accuracy, 4),
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "Specificity": round(specificity, 4),
        "F1 Score": round(f1_score, 4)
    }

first_metrics = compute_metrics(first_model)
rnd_metrics = compute_metrics(rnd_model)

results_df = pd.DataFrame({
    "Metric": list(first_metrics.keys()),
    "First Model": list(first_metrics.values()),
    "RND": list(rnd_metrics.values())
})

print(results_df.to_string(index=False))

```

The First Model correctly identified all 271 true positives, achieving 100% recall but only 0.97% precision due to 27,606 false positives. In contrast, the RND model predicted no positives, resulting in perfect specificity and 99.02% accuracy, but 0% recall and no ability to detect actual clicks. Although the First Model's accuracy was just 1.03%, it was more useful than the RND model because it captured all true click events. However, its extremely low precision highlights inefficiency, as most predicted clicks were incorrect. This comparison shows that in imbalanced datasets, metrics like precision, recall, and F1 score are more informative than accuracy alone


### Model Comparison

#### Cost Information
* Cost per 1,000 video impressions (CPM) is $10
* Conversion to sign-up as a TZ game player after clicking on an ad is 5%
* The expected CLV of customers that sign-up with TZ after clicking on an ad is approximately $25
* The total cost of the data from Vneta is $50K
* The total cost charged for the data science consulting services by Vneta is $150K

``` {python}
cpm = 10 # cost per 1000 video impression
conversion_rate= 0.05   # conversion to sign up with TZ after clicking on an ad
clv= 25 # expected clv of customers that sign up with TZ after clicking on an ad
total_impressions = 20_000_000 # given in the problem above
additional_cost_VNETA = 50_000 # cost of the data from VNETA DATA
additional_cost_Consulting= 150_000 #cost of thr consulting services by VNETA
additional_cost_spamming= 0 #cost for spamming with no VNETA involve

def calculate_break_even_response_rate(cpm,conversion_rate, clv, total_impressions,additional_cost):
    total_cost = (total_impressions/1000) *cpm +additional_cost
    margin = total_impressions * conversion_rate * clv
    break_even_rate_of_response= total_cost/margin
    return break_even_rate_of_response

break_even_response_rate_spamming= calculate_break_even_response_rate(cpm,conversion_rate, clv, total_impressions, additional_cost_spamming)
break_even_response_rate_spamming
```

``` {python}
tz_gaming= tz_test
tz_gaming["target_logit"] = tz_gaming["pred_logit"] > break_even_response_rate_spamming
tz_gaming["target_rnd"] = tz_gaming["pred_rnd"]> break_even_response_rate_spamming
tz_gaming["target_vneta"]= tz_gaming["pred_vneta"] >break_even_response_rate_spamming
tz_gaming
```

#### Spamming
``` {python}
total_succesful_clicks= tz_gaming[(tz_gaming["click_yes"]== 1)].shape[0]
total_succesful_clicks
total_costs = (tz_gaming.shape[0]/1000)*cpm
total_costs
total_revenue= total_succesful_clicks*conversion_rate*clv
total_revenue
profit_spam =total_revenue- total_costs
profit_spam
rome_spam= (profit_spam/total_costs)
rome_spam
print(profit_spam, rome_spam)

```

#### LOGIT
```{python}
total_succesful_clicks = tz_gaming[(tz_gaming["target_logit"] == True) & (tz_gaming["click_yes"]== 1)].shape[0]
total_succesful_clicks
total_costs = (tz_gaming[(tz_gaming["target_logit"]== True)].shape[0]/1000)*cpm
total_costs
total_revenue= total_succesful_clicks*conversion_rate*clv
total_revenue
profit_logit =total_revenue- total_costs
profit_logit
rome_logit= (profit_logit/total_costs)
rome_logit
print(profit_logit, rome_logit)
```

#### RND
```{python}
total_succesful_clicks = tz_gaming[(tz_gaming["target_rnd"] == True) & (tz_gaming["click_yes"]== 1)].shape[0]
total_succesful_clicks
total_costs = (tz_gaming[(tz_gaming["target_rnd"]== True)].shape[0]/1000)*cpm
total_costs
total_revenue= total_succesful_clicks*conversion_rate*clv
total_revenue
profit_rnd =total_revenue- total_costs
profit_rnd
rome_rnd= (profit_rnd/total_costs)
rome_rnd
print(profit_rnd, rome_rnd)
```

#### VNETA
```{python}
total_succesful_clicks = tz_gaming[(tz_gaming["target_vneta"] == True) & (tz_gaming["click_yes"]== 1)].shape[0]
total_succesful_clicks
total_costs = (tz_gaming[(tz_gaming["target_vneta"]== True)].shape[0]/1000)*cpm
total_costs
total_revenue= total_succesful_clicks*conversion_rate*clv
total_revenue
profit_vneta =total_revenue- total_costs
profit_vneta
rome_vneta= (profit_vneta/total_costs)
rome_vneta
print(profit_vneta, rome_vneta)
```

#### Summary


```{python}
tz_gaming["pred_spam"] = 1
tz_gaming["target_spam"] = True

mod_perf = pd.DataFrame(
    {
        "model": [
            "logit",
            "rnd",
            "vneta",
            "spam",
        ],
        "profit": [profit_logit, profit_rnd, profit_vneta, profit_spam],
        "ROME": [rome_logit, rome_rnd, rome_vneta, rome_spam],
    }
)
mod_perf
```

#### Analysis
The Vneta model demonstrates the highest ROME at 3.105933, making it the most efficient in marketing budget utilization. It generates a profit of 151.29, slightly lower than the Logit model but still highly effective. This model is ideal for scenarios where marketing efficiency and budget allocation are top priorities. On the other hand, the Logit model achieves the highest profit of 167.43, though its ROME is lower than that of the Vneta model, indicating reduced spending efficiency. It is best suited for cases where maximizing total profit is more important than efficiency. In contrast, both the Rnd and Spam models underperform in terms of profit and ROME compared to predictive models, suggesting that predictive strategies significantly outperform non-targeted methods. Overall, the Vneta model is recommended for its superior marketing efficiency, while the Logit model is preferred for maximizing profit. The choice between these two depends on whether ROI or total profit is the primary objective.

### Profit Comparison
```{python}
total_impressions_purchased = 20_000_000
test_sample= tz_gaming.shape[0]
test_sample
logit = (profit_logit /test_sample)* total_impressions_purchased
rnd= (profit_rnd/test_sample) * total_impressions_purchased
vneta= (profit_vneta/test_sample) * total_impressions_purchased
spam= (profit_spam/test_sample) * total_impressions_purchased

logit, rnd, vneta, spam

```

### ROME Comparison
```{python}
total_costs = (tz_gaming[(tz_gaming["target_logit"]== True)].shape[0]/1000)*cpm
rome_logit = logit/total_costs

total_costs = (tz_gaming[(tz_gaming["target_rnd"]== True)].shape[0]/1000)*cpm
rome_rnd= logit/total_costs

total_costs = (tz_gaming[(tz_gaming["target_vneta"]== True)].shape[0]/1000)*cpm
rome_vneta = vneta/total_costs

total_costs = (tz_gaming.shape[0]/1000)*cpm
rome_spam = spam/total_costs 

rome_logit, rome_rnd, rome_vneta, rome_logit
```

#### Profit and ROME Summary
```{python}
mod_perf_20M = pd.DataFrame(
    {
        "model": [
            "logit",
            "rnd",
            "vneta",
            "spam",
        ],
        "profit": [logit, rnd, vneta, spam],
        "ROME": [rome_logit, rome_rnd, rome_vneta, rome_spam],
    }
)
mod_perf_20M
```

## Conclusion
The Logit model leads in profit generation with $119,793.94, making it the top choice for revenue maximization, though its ROME stands at 1100.84, which, while strong, is not the highest. The Rnd model lags behind with a profit of $42,914.89 and a ROME of 429.73, reflecting lower efficiency and profitability. Similarly, the Spam model records $42,371.12 in profit, closely matching the Rnd model, but has the lowest ROME at 151.579877, making it the least effective approach. The Vneta model, on the other hand, secures a high profit of $108,245.98 and boasts the highest ROME at 2222.253, demonstrating superior marketing efficiency. This makes Vneta the optimal choice for balancing profit and marketing spend efficiency. Given its outstanding ROME, the Vneta model is the primary recommendation for maximizing investment returns. However, the Logit model remains a solid alternative for cases where absolute profit takes precedence over efficiency. The new data aligns with previous recommendations, reaffirming Vneta’s leadership in efficiency despite slightly lower profits than the Logit model. The results confirm that predictive models significantly outperform non-targeted approaches like the Rnd and Spam models. Ultimately, the Vneta model is best for those prioritizing a balance of high profit and peak efficiency, while the Logit model is the go-to option for pure profit maximization.  