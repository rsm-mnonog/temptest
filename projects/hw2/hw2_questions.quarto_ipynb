{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Poisson Regression Examples\"\n",
        "description: \"Poisson Regression Examples\"\n",
        "author: \"Mario Nonog\"\n",
        "date: today\n",
        "callout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\n",
        "theme: cosmo\n",
        "image: \"other_docs/HW_PHOTO.jpg\"\n",
        "---\n",
        "\n",
        "\n",
        "## Blueprinty Case Study\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty's software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty's software and after using it. Unfortunately, such data is not available. \n",
        "\n",
        "However, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm's number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty's software. The marketing team would like to use this data to make the claim that firms using Blueprinty's software are more successful in getting their patent applications approved.\n",
        "\n",
        "\n",
        "### Data\n",
        "\n",
        "\n",
        "\n",
        "<!-- # _todo: Read in data._ -->"
      ],
      "id": "a585d67a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Load data\n",
        "airbnb= pd.read_csv('other_docs/airbnb.csv')\n",
        "blueprinty= pd.read_csv('other_docs/blueprinty.csv')\n",
        "\n",
        "print(\"Airbnb Data Preview:\")\n",
        "print(airbnb.head())\n",
        "\n",
        "print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
        "\n",
        "print(\"Blueprinty Data Preview:\")\n",
        "print(blueprinty.head())\n",
        "\n",
        "# print(airbnb.columns)\n",
        "# print(blueprinty.columns)\n"
      ],
      "id": "40ff26fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- _todo: Compare histograms and means of number of patents by customer status. What do you observe?_ -->"
      ],
      "id": "135f2ccb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure correct type\n",
        "blueprinty['iscustomer'] = blueprinty['iscustomer'].astype(int)\n",
        "\n",
        "# Filter groups correctly\n",
        "group_0 = blueprinty[blueprinty['iscustomer'] == 0]['patents'].dropna()\n",
        "group_1 = blueprinty[blueprinty['iscustomer'] == 1]['patents'].dropna()\n",
        "\n",
        "# Diagnostics\n",
        "print(\"Group 0 count:\", len(group_0))\n",
        "print(\"Group 1 count:\", len(group_1))\n",
        "\n",
        "# Mean number of patents\n",
        "grouped_means = blueprinty.groupby('iscustomer')['patents'].mean()\n",
        "print(\"Mean number of patents by customer status:\")\n",
        "print(grouped_means)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(group_0, bins=10, alpha=0.6, label='Non-Customer')\n",
        "plt.hist(group_1, bins=10, alpha=0.6, label='Customer')\n",
        "plt.title('Histogram of Patents by Customer Status')\n",
        "plt.xlabel('Number of Patents')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Customer Status')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "9b22c498",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Observations\n",
        "\n",
        "- **Right-Skewed Distribution**: Most individuals in both groups hold fewer patents, with frequency dropping as patent count increases.\n",
        "- **Non-Customers Clustered at Lower Counts**: Non-Customers (blue bars) are more concentrated in the 0‚Äì3 patent range.\n",
        "- **Customers Show Higher Patent Counts**: Customers (orange bars) are more spread out and more represented in the 4‚Äì9 patent range.\n",
        "- **Overlap Exists**: Both groups overlap between 2‚Äì6 patents, but customers have a longer right tail.\n",
        "- **Few Outliers**: Some individuals in both groups have 10+ patents, though these cases are rare.\n",
        "\n",
        "### üß† Interpretation\n",
        "Although non-customers are more numerous, they are concentrated at lower patent counts.\n",
        "Customers, despite being fewer in number, are more represented at higher patent levels, suggesting that customers have a higher average number of patents ‚Äî which matches the earlier mean comparison.\n",
        "\n",
        "These patterns suggest that customers tend to have more patents on average compared to non-customers. This aligns with earlier mean comparisons and may imply greater innovation or productivity among customers.\n",
        "\n",
        "Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n",
        "\n",
        "<!-- _todo: Compare regions and ages by customer status. What do you observe?_ -->\n",
        "\n",
        "## üó∫Ô∏è Region and Age Comparison by Customer Status\n",
        "\n",
        "### üî¢ Summary Statistics"
      ],
      "id": "83f195e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Grouped summary of ages\n",
        "age_summary = blueprinty.groupby('iscustomer')['age'].describe()\n",
        "print(\"Age Summary by Customer Status:\")\n",
        "print(age_summary)\n",
        "\n",
        "# Region counts by customer status\n",
        "region_counts = blueprinty.groupby(['iscustomer', 'region']).size().unstack(fill_value=0)\n",
        "print(\"\\nRegion Counts by Customer Status:\")\n",
        "print(region_counts)"
      ],
      "id": "ddbd2fff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Interpretation by Table: Age and Region by Customer Status\n",
        "Customers tend to be slightly older (mean age 26.9 vs. 26.1) and more age-diverse than non-customers. Regionally, the Northeast has the highest concentration of customers, even exceeding the number of non-customers there. In all other regions, non-customers dominate, suggesting a geographic pattern in customer engagement.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Age Distribution by Customer Status"
      ],
      "id": "7e181d4f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ensure correct type for filtering\n",
        "blueprinty['iscustomer'] = blueprinty['iscustomer'].astype(int)\n",
        "\n",
        "# Prepare data subsets using integer comparison\n",
        "group_0 = blueprinty[blueprinty['iscustomer'] == 0]['age'].dropna()\n",
        "group_1 = blueprinty[blueprinty['iscustomer'] == 1]['age'].dropna()\n",
        "\n",
        "# Plot histogram and KDE separately\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Histograms\n",
        "plt.hist(group_0, bins=30, alpha=0.5, density=True, label='Non-Customer')\n",
        "plt.hist(group_1, bins=30, alpha=0.5, density=True, label='Customer')\n",
        "\n",
        "# KDEs\n",
        "sns.kdeplot(group_0, label='Non-Customer KDE', linewidth=2)\n",
        "sns.kdeplot(group_1, label='Customer KDE', linewidth=2)\n",
        "\n",
        "# Labels and formatting\n",
        "plt.title('Age Distribution by Customer Status')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Density')\n",
        "plt.legend(title='Customer Status')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b5f2f519",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Interpretation: Age Distribution by Customer Status\n",
        "\n",
        "The age distribution shows that **non-customers** are more concentrated around the mid-20s, while **customers** have a flatter and slightly more spread-out distribution. The **KDE curves** reinforce this, with the customer curve (red) showing more density in older age ranges (30+), whereas the non-customer curve (green) peaks earlier and drops off faster. This suggests that customers are generally **slightly older and more age-diverse** than non-customers.\n",
        "\n",
        "---\n",
        "\n",
        "### üìç Region Breakdown by Customer Status\n",
        "\n",
        "## üìä Region Breakdown by Customer Status"
      ],
      "id": "4f4d9e93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fix the data type and map labels\n",
        "region_plot = blueprinty.copy()\n",
        "region_plot['iscustomer'] = region_plot['iscustomer'].astype(int)\n",
        "region_plot['customer_label'] = region_plot['iscustomer'].map({0: 'Non-Customer', 1: 'Customer'})\n",
        "\n",
        "# Count and reshape data\n",
        "region_ct = region_plot.groupby(['region', 'customer_label']).size().unstack(fill_value=0)\n",
        "\n",
        "# Plot\n",
        "region_ct.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
        "plt.title('Region Breakdown by Customer Status')\n",
        "plt.xlabel('Region')\n",
        "plt.ylabel('Count')\n",
        "plt.legend(title='Customer Status')\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "id": "3f7236ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Interpretation: Region Breakdown by Customer Status\n",
        "\n",
        "The stacked bar chart reveals clear regional patterns in customer status. The **Northeast** stands out with the **largest customer base**, where customers even outnumber non-customers ‚Äî a unique trend not seen in other regions. In contrast, all other regions, especially the **Midwest** and **Southwest**, have a significantly higher number of non-customers, suggesting that customer engagement is **regionally concentrated** and strongest in the Northeast.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Estimation of Simple Poisson Model\n",
        "\n",
        "Since our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n",
        "\n",
        "<!-- _todo: Write down mathematically the likelihood for_ $Y \\sim \\text{Poisson}(\\lambda)$. Note that $f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!$.\n",
        "\n",
        "_todo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example:_\n",
        "\n",
        "```\n",
        "poisson_loglikelihood <- function(lambda, Y){\n",
        "   ...\n",
        "}\n",
        "```\n",
        "\n",
        "_todo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y)._\n",
        "\n",
        "_todo: If you're feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which \"feels right\" because the mean of a Poisson distribution is lambda._\n",
        "\n",
        "_todo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python._ -->\n",
        "\n",
        "### üß† Likelihood Function for Poisson\n",
        "\n",
        "For a Poisson-distributed variable \\( Y \\sim \\text{Poisson}(\\lambda) \\), the likelihood function is:\n",
        "\n",
        "\\[\n",
        "\\mathcal{L}(\\lambda | Y) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\n",
        "\\]\n",
        "\n",
        "Taking the log gives us the **log-likelihood**:\n",
        "\n",
        "\\[\n",
        "\\log \\mathcal{L}(\\lambda | Y) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log(\\lambda) - \\log(Y_i!) \\right)\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "### üßÆ Code: Poisson Log-Likelihood Function"
      ],
      "id": "4852e705"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from scipy.special import gammaln  # use this instead of factorial in log\n",
        "\n",
        "# Observed data\n",
        "Y = blueprinty['patents'].dropna().astype(int).values\n",
        "\n",
        "# Log-likelihood function\n",
        "def poisson_loglikelihood(lambda_, Y):\n",
        "    if lambda_ <= 0:\n",
        "        return -np.inf\n",
        "    return np.sum(-lambda_ + Y * np.log(lambda_) - gammaln(Y + 1))\n",
        "\n",
        "# Vectorized version for plotting\n",
        "def poisson_loglikelihood_vec(lambda_, Y):\n",
        "    lambda_ = np.asarray(lambda_)\n",
        "    return np.array([\n",
        "        np.sum(-l + Y * np.log(l) - gammaln(Y + 1))\n",
        "        if l > 0 else -np.inf for l in lambda_\n",
        "    ])"
      ],
      "id": "dfb3a0e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üìä Plot: Log-Likelihood over Lambda"
      ],
      "id": "3444c671"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lambda_vals = np.linspace(0.1, 10, 200)\n",
        "log_liks = poisson_loglikelihood_vec(lambda_vals, Y)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(lambda_vals, log_liks)\n",
        "plt.title('Poisson Log-Likelihood for Varying Œª')\n",
        "plt.xlabel('Œª')\n",
        "plt.ylabel('Log-Likelihood')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "a9f6ee86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ‚úèÔ∏è Analytically Solving for MLE\n",
        "\n",
        "Taking the derivative of the log-likelihood and setting it to zero yields:\n",
        "\n",
        "\\[\n",
        "\\frac{\\partial}{\\partial \\lambda} \\log \\mathcal{L} = -n + \\frac{\\sum Y_i}{\\lambda} = 0 \\Rightarrow \\lambda_{\\text{MLE}} = \\bar{Y}\n",
        "\\]\n",
        "\n",
        "This makes intuitive sense, as the **mean** of a Poisson distribution is its only parameter.\n",
        "\n",
        "---\n",
        "\n",
        "### üîß Numerical Optimization"
      ],
      "id": "4201dfc7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Negative log-likelihood for optimization\n",
        "def neg_loglikelihood(lambda_):\n",
        "    return -poisson_loglikelihood(lambda_[0], Y)\n",
        "\n",
        "# Optimize\n",
        "result = minimize(neg_loglikelihood, x0=[1.0], bounds=[(1e-5, None)])\n",
        "lambda_mle = result.x[0]\n",
        "\n",
        "print(f\"MLE for lambda: {lambda_mle:.4f}\")"
      ],
      "id": "e6dc5d4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### ‚úÖ Conclusion\n",
        "\n",
        "We estimated the Poisson parameter \\( \\lambda \\) via maximum likelihood using both **analytical** and **numerical** approaches. As expected, the MLE aligns with the sample mean of the observed patent counts.\n",
        "\n",
        "\n",
        "### Estimation of Poisson Regression Model\n",
        "\n",
        "Next, we extend our simple Poisson model to a Poisson Regression Model such that $Y_i = \\text{Poisson}(\\lambda_i)$ where $\\lambda_i = \\exp(X_i'\\beta)$. The interpretation is that the success rate of patent awards is not constant across all firms ($\\lambda$) but rather is a function of firm characteristics $X_i$. Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n",
        "\n",
        "<!-- _todo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that_ $\\lambda_i = e^{X_i'\\beta}$. _For example:_\n",
        "\n",
        "```\n",
        "poisson_regression_likelihood <- function(beta, Y, X){\n",
        "   ...\n",
        "}\n",
        "```\n",
        "\n",
        "_todo: Use your function along with R's optim() or Python's sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1's to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors._\n",
        "\n",
        "_todo: Check your results using R's glm() function or Python sm.GLM() function._\n",
        "\n",
        "_todo: Interpret the results._ \n",
        "\n",
        "_todo: What do you conclude about the effect of Blueprinty's software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences._ -->\n",
        "\n",
        "## üéØ Estimate the Effect of Blueprinty's Software"
      ],
      "id": "e919c356"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data\n",
        "df = blueprinty.copy()\n",
        "df = df.dropna(subset=['patents', 'age', 'region', 'iscustomer'])\n",
        "df['iscustomer'] = df['iscustomer'].astype(int)\n",
        "df['age_centered'] = df['age'] - df['age'].mean()\n",
        "df['age2_centered'] = df['age_centered'] ** 2\n",
        "df['intercept'] = 1\n",
        "\n",
        "# Create dummy variables for region (drop first to avoid multicollinearity)\n",
        "region_dummies = pd.get_dummies(df['region'], drop_first=True)\n",
        "\n",
        "# Combine into design matrix and ensure all columns are numeric\n",
        "X_sm = pd.concat([\n",
        "    df[['intercept', 'age_centered', 'age2_centered', 'iscustomer']],\n",
        "    region_dummies\n",
        "], axis=1).astype(float)  # ‚úÖ Convert all to float\n",
        "\n",
        "# Outcome variable\n",
        "Y = df['patents'].astype(float)\n",
        "\n",
        "# Fit Poisson model\n",
        "model = sm.GLM(Y, X_sm, family=sm.families.Poisson())\n",
        "glm_results = model.fit()\n",
        "\n",
        "# Create datasets with iscustomer set to 0 and 1\n",
        "X_0 = X_sm.copy()\n",
        "X_0['iscustomer'] = 0\n",
        "X_1 = X_sm.copy()\n",
        "X_1['iscustomer'] = 1\n",
        "\n",
        "# Predict outcomes\n",
        "y_pred_0 = glm_results.predict(X_0)\n",
        "y_pred_1 = glm_results.predict(X_1)\n",
        "\n",
        "# Calculate average treatment effect\n",
        "average_treatment_effect = np.mean(y_pred_1 - y_pred_0)\n",
        "print(\"Average predicted increase in patents from using Blueprinty's software:\")\n",
        "print(average_treatment_effect)"
      ],
      "id": "76cb3379",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Interpretation: Effect of Blueprinty's Software on Patent Success\n",
        "\n",
        "To assess the effect of Blueprinty's software, we estimated a Poisson regression model where the expected number of patents for each firm depends on age, age squared, region, and customer status. Because the coefficients in a Poisson model are on the log scale, we simulated two scenarios:\n",
        "\n",
        "- One where all firms are treated as **non-customers** (`iscustomer = 0`)\n",
        "- One where all firms are treated as **customers** (`iscustomer = 1`)\n",
        "\n",
        "Using the fitted model, we predicted the number of patents under both scenarios and computed the **difference** for each firm.\n",
        "\n",
        "### ‚úÖ Result\n",
        "\n",
        "The **average treatment effect** of using Blueprinty's software is:"
      ],
      "id": "e022998a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Average predicted increase in patents from using Blueprinty's software: {average_treatment_effect:.3f}\")"
      ],
      "id": "0df1a6c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This means that, **on average, firms that are Blueprinty customers are predicted to earn approximately 0.79 more patents over 5 years** than if they were not customers ‚Äî holding all other factors constant.\n",
        "\n",
        "### üß† Conclusion\n",
        "\n",
        "Despite the customer coefficient being on the log scale and not directly interpretable, this simulation reveals a **positive and practically meaningful effect** of using Blueprinty's software on patent output. This supports the hypothesis that access to Blueprinty's tools may enhance firm innovation or efficiency.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## AirBnB Case Study\n",
        "\n",
        "### Introduction\n",
        "\n",
        "AirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City.  The data include the following variables:\n",
        "\n",
        ":::: {.callout-note collapse=\"true\"}\n",
        "### Variable Definitions\n",
        "\n",
        "    - `id` = unique ID number for each unit\n",
        "    - `last_scraped` = date when information scraped\n",
        "    - `host_since` = date when host first listed the unit on Airbnb\n",
        "    - `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n",
        "    - `room_type` = Entire home/apt., Private room, or Shared room\n",
        "    - `bathrooms` = number of bathrooms\n",
        "    - `bedrooms` = number of bedrooms\n",
        "    - `price` = price per night (dollars)\n",
        "    - `number_of_reviews` = number of reviews for the unit on Airbnb\n",
        "    - `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n",
        "    - `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n",
        "    - `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n",
        "    - `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "<!-- _todo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided._ -->\n",
        "\n",
        "\n",
        "## üè† Airbnb Listing Analysis: Modeling Bookings via Review Counts\n",
        "\n",
        "We assume that the number of **reviews** serves as a reasonable proxy for the number of **bookings** a listing receives. We aim to explore and model how listing features (e.g., price, room type, amenities) relate to this outcome using a Poisson regression framework.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç Exploratory Data Analysis and Cleaning"
      ],
      "id": "f735081a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data\n",
        "airbnb = airbnb\n",
        "\n",
        "# Preview\n",
        "print(airbnb.head())\n",
        "\n",
        "# Histogram of number of reviews\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(airbnb['number_of_reviews'], bins=50, kde=False)\n",
        "plt.title('Distribution of Review Counts')\n",
        "plt.xlabel('Number of Reviews')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "5b62cb0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üßπ Data Preparation"
      ],
      "id": "2ad86f74"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select and clean relevant variables\n",
        "df = airbnb[['number_of_reviews', 'days', 'room_type', 'bathrooms', 'bedrooms', \n",
        "             'price', 'review_scores_cleanliness', 'review_scores_location', \n",
        "             'review_scores_value', 'instant_bookable']].copy()\n",
        "\n",
        "# Drop rows with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert instant_bookable from \"t\"/\"f\" to binary\n",
        "df['instant_bookable'] = df['instant_bookable'].map({'t': 1, 'f': 0})\n",
        "\n",
        "# Create dummy variables for room_type\n",
        "room_dummies = pd.get_dummies(df['room_type'], drop_first=True)\n",
        "\n",
        "# Combine into final design matrix\n",
        "import statsmodels.api as sm\n",
        "\n",
        "X = pd.concat([\n",
        "    df[['days', 'bathrooms', 'bedrooms', 'price', \n",
        "        'review_scores_cleanliness', 'review_scores_location', \n",
        "        'review_scores_value', 'instant_bookable']],\n",
        "    room_dummies\n",
        "], axis=1)\n",
        "X = sm.add_constant(X)\n",
        "Y = df['number_of_reviews']"
      ],
      "id": "618be36e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### üìà Poisson Regression: Number of Reviews"
      ],
      "id": "813b0545"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensure all variables are numeric to avoid ValueError\n",
        "X = X.astype(float)\n",
        "Y = Y.astype(float)\n",
        "\n",
        "# Fit Poisson regression model\n",
        "poisson_model = sm.GLM(Y, X, family=sm.families.Poisson())\n",
        "poisson_results = poisson_model.fit()\n",
        "\n",
        "# View regression output\n",
        "print(poisson_results.summary())"
      ],
      "id": "c74bd924",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìå Example: Interpreting a Poisson Regression Coefficient\n",
        "\n",
        "In a Poisson regression model, coefficients represent changes in the **log of the expected count** (e.g., number of reviews). To interpret them in a more intuitive way, we exponentiate the coefficient to express the effect as a **percentage change**.\n",
        "\n",
        "For example:\n",
        "\n",
        "> **Holding all other variables constant**, a 1-point increase in the cleanliness review score is associated with an approximate **11.31% increase** in the expected number of reviews.\n",
        "\n",
        "This interpretation comes from:\n",
        "\n",
        "\\[\n",
        "\\text{Percent change} = (\\exp(0.1131) - 1) \\times 100 \\approx 11.31\\%\n",
        "\\]\n",
        "\n",
        "You can apply the same method to interpret other variables in the model.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Interpretation of Results\n",
        "\n",
        "- **`days`**: The longer a listing has been active on Airbnb, the more reviews it accumulates ‚Äî as expected.\n",
        "- **`bedrooms`**: Listings with more bedrooms receive more reviews, likely reflecting larger or more attractive spaces.\n",
        "- **`bathrooms`**: Unexpectedly, more bathrooms are associated with slightly fewer reviews. This may reflect a subset of high-end listings with lower turnover.\n",
        "- **`price`**: A small negative relationship with reviews suggests that higher-priced listings may be booked less frequently.\n",
        "- **`instant_bookable`**: If significant, this would indicate that convenience boosts bookings.\n",
        "- **`room_type`**: Dummy variables capture how listing type (e.g., Private Room, Shared Room) affects bookings relative to the base category (Entire home/apt).\n",
        "\n",
        "> ‚úÖ **Note**: Coefficients in Poisson regression are on a **log scale**. For interpretability, exponentiating them gives the **multiplicative effect** on the expected number of reviews.\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Conclusion\n",
        "\n",
        "This model helps us understand how listing attributes affect booking frequency. By identifying drivers of higher review counts (e.g., instant booking, number of bedrooms, lower price), hosts and platforms like Airbnb can make more data-informed decisions.\n"
      ],
      "id": "6268de0c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/conda/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}